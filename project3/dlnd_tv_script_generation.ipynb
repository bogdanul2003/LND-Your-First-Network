{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TV Script Generation\n",
    "In this project, you'll generate your own [Simpsons](https://en.wikipedia.org/wiki/The_Simpsons) TV scripts using RNNs.  You'll be using part of the [Simpsons dataset](https://www.kaggle.com/wcukierski/the-simpsons-by-the-data) of scripts from 27 seasons.  The Neural Network you'll build will generate a new TV script for a scene at [Moe's Tavern](https://simpsonswiki.com/wiki/Moe's_Tavern).\n",
    "## Get the Data\n",
    "The data is already provided for you.  You'll be using a subset of the original dataset.  It consists of only the scenes in Moe's Tavern.  This doesn't include other versions of the tavern, like \"Moe's Cavern\", \"Flaming Moe's\", \"Uncle Moe's Family Feed-Bag\", etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import helper\n",
    "\n",
    "data_dir = './data/simpsons/moes_tavern_lines.txt'\n",
    "text = helper.load_data(data_dir)\n",
    "# Ignore notice, since we don't use it for analysing the data\n",
    "text = text[81:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "Play around with `view_sentence_range` to view different parts of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Stats\n",
      "Roughly the number of unique words: 11492\n",
      "Number of scenes: 262\n",
      "Average number of sentences in each scene: 15.248091603053435\n",
      "Number of lines: 4257\n",
      "Average number of words in each line: 11.50434578341555\n",
      "\n",
      "The sentences 0 to 10:\n",
      "Moe_Szyslak: (INTO PHONE) Moe's Tavern. Where the elite meet to drink.\n",
      "Bart_Simpson: Eh, yeah, hello, is Mike there? Last name, Rotch.\n",
      "Moe_Szyslak: (INTO PHONE) Hold on, I'll check. (TO BARFLIES) Mike Rotch. Mike Rotch. Hey, has anybody seen Mike Rotch, lately?\n",
      "Moe_Szyslak: (INTO PHONE) Listen you little puke. One of these days I'm gonna catch you, and I'm gonna carve my name on your back with an ice pick.\n",
      "Moe_Szyslak: What's the matter Homer? You're not your normal effervescent self.\n",
      "Homer_Simpson: I got my problems, Moe. Give me another one.\n",
      "Moe_Szyslak: Homer, hey, you should not drink to forget your problems.\n",
      "Barney_Gumble: Yeah, you should only drink to enhance your social skills.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "view_sentence_range = (0, 10)\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "print('Dataset Stats')\n",
    "print('Roughly the number of unique words: {}'.format(len({word: None for word in text.split()})))\n",
    "scenes = text.split('\\n\\n')\n",
    "print('Number of scenes: {}'.format(len(scenes)))\n",
    "sentence_count_scene = [scene.count('\\n') for scene in scenes]\n",
    "print('Average number of sentences in each scene: {}'.format(np.average(sentence_count_scene)))\n",
    "\n",
    "sentences = [sentence for scene in scenes for sentence in scene.split('\\n')]\n",
    "print('Number of lines: {}'.format(len(sentences)))\n",
    "word_count_sentence = [len(sentence.split()) for sentence in sentences]\n",
    "print('Average number of words in each line: {}'.format(np.average(word_count_sentence)))\n",
    "\n",
    "print()\n",
    "print('The sentences {} to {}:'.format(*view_sentence_range))\n",
    "print('\\n'.join(text.split('\\n')[view_sentence_range[0]:view_sentence_range[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocessing Functions\n",
    "The first thing to do to any dataset is preprocessing.  Implement the following preprocessing functions below:\n",
    "- Lookup Table\n",
    "- Tokenize Punctuation\n",
    "\n",
    "### Lookup Table\n",
    "To create a word embedding, you first need to transform the words to ids.  In this function, create two dictionaries:\n",
    "- Dictionary to go from the words to an id, we'll call `vocab_to_int`\n",
    "- Dictionary to go from the id to word, we'll call `int_to_vocab`\n",
    "\n",
    "Return these dictionaries in the following tuple `(vocab_to_int, int_to_vocab)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'enhance', 'eh', 'is', \"i'll\", \"moe's\", 'skills', 'hold', 'rotch', 'on', 'these', 'the', 'my', 'not', 'elite', 'anybody', 'where', 'effervescent', 'has', 'another', 'me', 'self', 'i', 'forget', 'hello', 'carve', 'barney_gumble', 'with', 'puke', 'only', 'and', 'lately', 'listen', 'an', 'matter', 'there', 'moe', \"i'm\", 'homer_simpson', 'should', 'hey', 'normal', 'you', 'social', 'days', 'mike', 'catch', 'one', 'homer', 'got', 'of', 'pick', 'yeah', 'moe_szyslak', 'bart_simpson', 'drink', 'meet', 'seen', 'last', 'back', 'give', 'tavern', 'ice', 'little', 'your', 'check', 'whats', 'problems', 'to', \"you're\", 'name', 'gonna'}\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import problem_unittests as tests\n",
    "\n",
    "def create_lookup_tables(text):\n",
    "    \"\"\"\n",
    "    Create lookup tables for vocabulary\n",
    "    :param text: The text of tv scripts split into words\n",
    "    :return: A tuple of dicts (vocab_to_int, int_to_vocab)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    words = set(text)\n",
    "    print(words)\n",
    "    vocab_to_int = {c: i for i, c in enumerate(words)}\n",
    "    int_to_vocab = dict(enumerate(words))\n",
    "    return (vocab_to_int, int_to_vocab)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_create_lookup_tables(create_lookup_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Tokenize Punctuation\n",
    "We'll be splitting the script into a word array using spaces as delimiters.  However, punctuations like periods and exclamation marks make it hard for the neural network to distinguish between the word \"bye\" and \"bye!\".\n",
    "\n",
    "Implement the function `token_lookup` to return a dict that will be used to tokenize symbols like \"!\" into \"||Exclamation_Mark||\".  Create a dictionary for the following symbols where the symbol is the key and value is the token:\n",
    "- Period ( . )\n",
    "- Comma ( , )\n",
    "- Quotation Mark ( \" )\n",
    "- Semicolon ( ; )\n",
    "- Exclamation mark ( ! )\n",
    "- Question mark ( ? )\n",
    "- Left Parentheses ( ( )\n",
    "- Right Parentheses ( ) )\n",
    "- Dash ( -- )\n",
    "- Return ( \\n )\n",
    "\n",
    "This dictionary will be used to token the symbols and add the delimiter (space) around it.  This separates the symbols as it's own word, making it easier for the neural network to predict on the next word. Make sure you don't use a token that could be confused as a word. Instead of using the token \"dash\", try using something like \"||dash||\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'--': '||dash||', '\\n': '||newline||', '.': '||dott||', ')': '||rparenthese||', '(': '||lparenthese||', '?': '||questionmark||', ';': '||pointandcoma||', ',': '||comma||', '\"': '||qutes||', '!': '||exclamationpoint||'}\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def token_lookup():\n",
    "    \"\"\"\n",
    "    Generate a dict to turn punctuation into a token.\n",
    "    :return: Tokenize dictionary where the key is the punctuation and the value is the token\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    ret = {}\n",
    "    ret[\".\"] = \"||dott||\"\n",
    "    ret[\",\"] = \"||comma||\"\n",
    "    ret['\"'] = \"||qutes||\"\n",
    "    ret[\";\"] = \"||pointandcoma||\"\n",
    "    ret[\"!\"] = \"||exclamationpoint||\"\n",
    "    ret[\"(\"] = \"||lparenthese||\"\n",
    "    ret[\")\"] = \"||rparenthese||\"\n",
    "    ret[\"--\"] = \"||dash||\"\n",
    "    ret[\"\\n\"] = \"||newline||\"\n",
    "    ret[\"?\"] = \"||questionmark||\"\n",
    "    print(ret)\n",
    "     \n",
    "    return ret\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_tokenize(token_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the data and save it to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'--': '||dash||', '\\n': '||newline||', '.': '||dott||', ')': '||rparenthese||', '(': '||lparenthese||', '?': '||questionmark||', ';': '||pointandcoma||', ',': '||comma||', '\"': '||qutes||', '!': '||exclamationpoint||'}\n",
      "{'padres', 'comic_book_guy:', 'nagurski', 'strawberry', 'roz:', \"larry's\", 'thomas', 'computer_voice_2:', 'barney-type', 'marge', \"what'd\", 'koji', 'refreshment', 'drunk', 'gets', 'chili', 'skinheads', 'cowboys', 'flag', 'guts', 'browns', 'flea:', 'above', 'dames', 'd', 'unrelated', \"family's\", 'enveloped', 'move', 'number', \"hole'\", 'bill_james:', 'stands', 'burnside', 'cushion', '||dash||', 'secret', 'handing', \"'round\", 'bowling', 'steinbrenner', 'gutenberg', 'richard', 'emergency', 'mediterranean', 'jackpot-thief', 'plants', 'comment', 'grampa_simpson:', 'trees', 'knit', 'rabbits', 'believer', 'drawn', 'cigarettes', 'clothes', 'eighty-five', \"raggin'\", 'privacy', 'ahead', 'line', 'coined', 'paris', 'cries', \"foolin'\", 'lights', \"spyin'\", 'lost', 'most', 'beast', 'kodos:', 'amazing', 'defected', 'serum', 'amanda', 'getup', 'memory', 'done', 'suing', '100', 'yes', 'sometime', 'pocket', 'ground', 'kinda', 'canoodling', 'hook', 'gig', 'hangs', 'cecil', 'severe', 'johnny', 'meteor', 'things', 'eighteen', 'effect', 'felt', 'fence', 'wa', 'barter', 'johnny_carson:', 'house', 'blank', 'hundred', 'actually', 'figured', 'tree_hoper:', 'friend', 'bet', 'exquisite', 'furious', 'modern', 'booze-bags', \"beggin'\", 'eight', 'conditioner', 'squeals', 'guzzles', 'laid', 'there', 'gumbo', 'should', 'schorr', 'delighted', 'philosophical', 'still', 'start', 'nor', 'mater', 'passenger', 'understand', 'bed', 'kl5-4796', 'anymore', 'as', 'manatee', 'fatso', 'arts', 'thinking', 'mt', 'festival', 'steak', 'strong', 'wine', 'coyly', 'mom', 'prettied', 'supplying', 'hm', 'invite', 'drinker', \"other's\", 'necklace', 'eats', \"waitin'\", 'choke', 'worth', 'suddenly', 'suspiciously', 'catch', 'flush', 'sidelines', 'taste', 'tester', 'test', 'kisses', 'whoa', 'rob', 'paparazzo', 'plant', 'results', 'interrupting', 'effervescent', 'specials', 'choice:', \"you'd\", 'wolveriskey', \"takin'\", 'needed', 'loves', 'football_announcer:', 'bake', 'murmurs', 'hilton', '35', 'wildfever', 'startled', 'action', 'staying', 'usually', \"jackpot's\", 'lance', 'stopped', 'strains', 'düffenbraus', 'match', 'waitress', 'neighbor', 'spiritual', 'make', 'yap', 'suspenders', 'rivalry', 'self-esteem', 'marriage', 'pre-game', 'scully', 'fake', 'contract', 'covers', 'bellyaching', 'soul-crushing', 'ask', 'twenty-five', 'screws', 'terrified', 'prize', 'hootie', 'quick', '-ry', \"cashin'\", 'bowie', 'clears', 'streetcorner', 'hired', 'drop', 'life', 'air', 'everyday', 'punkin', 'average-looking', 'flailing', 'scary', 'scratching', 'answering', \"linin'\", 'singers:', 'shack', 'accent', 'fast', 'sister', 'cow', 'numbers', 'nelson', \"'evening\", 'brick', 'muffled', 'twin', 'deadly', 'troubles', 'obsessive-compulsive', 'celebrate', 'offa', 'tobacky', 'menace', 'distance', 'mm-hmm', 'belt', 'rocks', 'intrigued', 'carl_carlson:', 'doll-baby', 'churchy', 'willy', 'lingus', 'safety', 'far', 'everywhere', 'hate', 'teams', 'diets', 'fonda', 'jerk', 'tavern', 'why', 'red', \"'im\", 'baseball', 'priceless', 'its', 'dad', 'wiping', 'complicated', 'trivia', 'giggles', 'states', 'four-drink', 'wide', 'natural', 'answered', 'divine', 'juke', 'yellow-belly', 'judge', 'mexican_duffman:', 'stagy', 'inanely', 'superhero', 'declan_desmond:', 'eliminate', 'childless', 'dollar', 'planning', 'mirthless', 'frankie', 'forever', \"tinklin'\", 'ivanna', 'fdic', 'assume', 'fonzie', 'urge', 'tsk', 'sponsor', 'scrubbing', 'man_with_tree_hat:', 'moxie', 'gamble', 'told', 'william', 'tactful', 'hide', 'winces', \"tony's\", 'aggravated', 'fail', 'hmm', 'pleading', 'now', 'gruff', 'landlord', 'jeff', 'mmm', 'drinks', 'whole', 'dea-d-d-dead', 'police', 'icy', 'genuinely', 'self-satisfied', \"crawlin'\", 'lofty', 'detecting', \"aristotle's\", 'bar:', 'where', 'dive', 'represents', 'dirge-like', 'filled', 'four-star', 'à', \"rustlin'\", 'tin', \"c'mom\", 'relaxed', 'buttons', 'marquee', 'bathroom', 'have', 'devastated', 'shakespeare', 'sued', 'lumpa', 'glyco-load', 'raccoons', 'j', 'nein', 'game', 'nobel', 'feed', 'nonchalant', \"money's\", 'another', 'dana_scully:', 'byrne', 'calmly', 'shores', 'once', 'type', 'led', 'position', '||exclamationpoint||', 'blind', 'creepy', 'gator', 'confused', 'fell', 'sickens', \"bashir's\", 'korea', 'thank', 'heavyweight', 'understanding', 'sponsoring', 'motorcycle', 'jams', 'grope', 'control', 'dexterous', 'guff', 'dentist', 'promised', \"secret's\", 'nectar', 'lorre', 'lousy', 'spend', 'coast', 'welcome', \"singin'\", 'premise', 'lenford', 'order', 'hare-brained', 'anywhere', 'only', 'beautiful', 'stiffening', 'housework', 'lindsay', 'hey', 'spamming', 'burns', 'golden', 'aiden', 'paid', 'belly-aching', \"wino's\", 'urban', 'bad', 'midge:', 'comedies', 'pity', 'jasper_beardly:', 'tear', 'regretted', 'loud', 'sniffs', 'uh-huh', 'kahlua', 'verticality', \"countin'\", 'diminish', 'scruffy_blogger:', 'disappointed', 'blame', 'error', 'mini-beret', 'weekly', 'incriminating', 'uhhhh', 'guys', 'donut', 'dimly', 'brainheaded', \"'cause\", 'lager', 'burt_reynolds:', 'newspaper', 'advantage', 'minus', 'plums', 'aged_moe:', 'david_byrne:', 'chest', 'eat', 'rueful', 'suck', 'fishing', 'wayne:', \"renee's\", \"feelin's\", 'raining', 'characteristic', 'tied', 'clipped', 'college', 'stained-glass', 'chorus:', 'event', 'highball', 'butt', \"it'd\", \"where'd\", 'created', 'clown-like', 'changing', 'sturdy', 'remote', \"tryin'\", 'academy', 'frozen', 'inserted', 'crisis', 'p-k', 'bolting', 'worry', 'frankenstein', 'kenny', 'probably', 'busiest', 'failed', 'sells', 'bums', 'depressant', 'looking', 'indifferent', 'price', 'tick', 'clone', 'hoping', 'reached', 'ratio', 'bauer', 'beefs', 'wazoo', 'finance', 'access', 'presently', 'patterns', 'haiti', 'mustard', 'agnes_skinner:', 'tolerable', 'admiration', 'protestantism', 'andrew', 'hillary', 'points', 'seamstress', 'one-hour', 'bliss', 'lucius', 'seymour', 'oil', 'standards', 'began', 'scotch', 'stock', \"lefty's\", 'gator:', 'crimes', 'effigy', 'trainers', 'feelings', 'bursts', 'land', 'christmas', 'compressions', 'slight', 'babies', 'knowing', 'burg', 'shades', 'der', 'slaves', 'dynamite', 'octa-', 'cockroach', 'sausage', 'beeps', 'off', 'is:', 'slipped', 'unfortunately', 'seemed', 'worldview', 'remembers', 'al_gore:', 'squeezed', 'coms', 'hunky', 'bartender', 'hearse', 'dear', 'boggs', 'perfume', 'full-blooded', 'term', 'disturbing', 'kick', 'chocolate', 'happy', 'barely', 'ruled', 'frightened', 'vengeful', 'incredulous', 'application', 'traitor', 'venom', 'liven', 'mitts', 'scum-sucking', 'really', 'gentleman:', 'meanwhile', 'lemonade', 'tv', 'tommy', 'small_boy:', 'oh-ho', 'kings', 'beady', 'boozehound', \"rentin'\", \"barney's\", 'homers', 'legend', 'fireworks', 'hobo', 'common', 'glorious', 'brooklyn', 'coy', \"england's\", 'declan', 'did', 'nope', \"drinkin'\", 'refinanced', 'pass', 'shopping', 'rumor', 'vodka', 'hooters', 'pajamas', 'book', 'john', 'either', 'ihop', 'flashing', 'pretzels', 'woe:', 'pictured', 'from', 'anything', 'planet', 'bottom', \"aren't\", 'c', 'motor', 'desperate', 'ech', 'a-b-', 'tv_father:', 'strongly', 'wells', \"they're\", 'witty', 'troy:', 'blocked', 'anguished', 'noggin', 'bon', 'decide', 'counterfeit', 'notably', 'chinese', 'shakes', 'thirty-nine', 'file', 'sponge:', 'slop', 'distaste', 'romantic', 'playhouse', 'poor', 'hosting', 'skoal', 'oughtta', \"coffee'll\", 'edna-lover-one-seventy-two', 'effervescence', 'loafers', 'artie_ziff:', 'fired', 'remodel', 'feminine', 'blooded', 'steamed', 'sixty-five', 'school', 'model', 'winner', 'side', 'alky', 'male_singers:', \"tree's\", 'housing', 'kills', 'island', 'anderson', 'follow', 'twelve', 'wins', 'dude', 'occasion', 'country', 'weary', 'musketeers', 'mortgage', \"can'tcha\", 'club', 'anxious', 'wiggle', 'ahem', 'goldarnit', 'hollye', 'zack', 'broom', 'urinal', 'crinkly', 'well-wisher', 'harmony', 'hollowed-out', 'impress', '||lparenthese||', 'fatty', 'nation', 'march', 'clear', 'teenage_barney:', 'grandmother', 'jaegermeister', 'nos', \"'bout\", 'prime', 'reads', 'sooo', 'winch', 'thousand', \"o'clock\", 'wisconsin', 'long', 'slab', 'swimming', 'sniper', 'blew', 'sticking-place', 'moe-heads', 'attracted', 'l', 'sarcastic', 'unfair', 'bitter', 'forced', 'baritone', 'wangs', 'temples', \"he'd\", 'blessing', \"wearin'\", 'confident', 'dawning', 'turns', 'hiring', 'conversations', 'polish', 'england', 'finale', 'drives', 'puke', 'remains', 'augustus', 'sit', 'super-nice', 'natured', 'duh', 'crowbar', 'jerks', 'slice', 'perverse', 'sheriff', 'escort', 'emotional', \"you're\", 'any', 'bee', 'prep', 'ram', 'wham', 'tidy', 'chance', 'shut', \"hangin'\", 'onassis', 'sour', 'mailbox', 'spied', 'cable', 'self', 'non-losers', 'exploiter', 'gentlemen', 'male_inspector:', 'row', 'cocktail', 'virility', \"havin'\", 'affectations', 'producers', 'praise', 'banks', 'ladies', 'pats', 'chow', 'catholic', 'teacher', 'very', 'adjust', 'proves', 'wearing', '_burns_heads:', 'showed', 'letters', 'anyway', 'screams', 'jay_leno:', 'flustered', 'thrown', 'mechanical', 'neon', 'cats', 'lenny:', 'moron', 'egg', 'in-in-in', 'firm', 'days', 'civil', \"disrobin'\", 'dropping', 'seem', 'drummer', 'gave', 'gil_gunderson:', 'located', 'frustrated', 'asking', 'engraved', 'solely', 'businessman_#1:', 'cauliflower', 'blue', 'enthusiastically', 'um', 'judge_snyder:', 'ivory', 'wall', 'manboobs', 'tenor:', 'crayola', 'selma', 'eva', 'lap', 'craft', 'release', 'comedy', 'whaaaa', 'dignity', 'professor_jonathan_frink:', 'murdoch', 'correction', 'people', 'religion', 'sloe', 'kid', 'au', 'market', '_kissingher:', 'maybe', 'studio', \"heat's\", 'recreate', 'earth', 'emporium', 'bon-bons', 'looked', \"choosin'\", 'interesting', 'women', 'especially', 'suicide', 'name:', 'crap', 'mob', 'buddha', 'course', 'remembering', 'triumphantly', 'nelson_muntz:', 'day', 'jebediah', 'art', 'moe-clone', 'actor', '8', 'hits', 'dice', 'gag', 'sincerely', 'smile:', \"bringin'\", 'doooown', 'swe-ee-ee-ee-eet', 'platinum', 'buyer', 'hungry', 'bags', 'swan', 'fwooof', 'weeks', 'flower', 'thanksgiving', 'immiggants', 'according', 'skirt', 'bannister', 'band', 'sniffing', 'drove', 'thankful', 'afford', 'vermont', 'head', 'ice', 'advertising', 'repressed', 'owes', 'loser', 'neck', 'team', \"handwriting's\", 'scatter', 'flanders:', \"we'll\", 'crushed', 'agent_johnson:', 'metal', 'mini-dumpsters', 'feat', 'sweden', \"pope's\", 'superior', 'sure', \"tootin'\", 'hose', 'dazed', 'sobs', 'worst', 'texan', \"spaghetti-o's\", 'housewife', 'scam', 'breath', 'latin', 'dumptruck', 'vulnerable', 'belch', 'jazz', 'appreciate', 'meal', 'strangles', 'restless', 'mccall', 'thorn', 'fledgling', 'bachelorette', \"stinkin'\", 'intimacy', 'unsourced', 'filed', 'malted', 'appointment', \"lady's\", 'mind', 'might', 'self-centered', 'amber', 'asleep', 'guilt', 'window', 'century', 'jack', 'reynolds', \"usin'\", 'preparation', 'steam', 'dog', 'ingrates', 'generously', 'trusted', 'perfunctory', 'fondly', 'tang', 'brewed', 'cobbling', 'wiggum', 'enter', 'tasty', 'sedaris', 'warily', 'sodas', 'fist', 'comeback', 'elder', 'wittgenstein', 'hopeful', 'clapping', \"pickin'\", 'strategizing', \"g'night\", 'good-looking', 'mel', 'dictating', 'indifference', 'guest', 'mind-numbing', 'inclination', 'ne', 'i', 'technical', 'spit', 'drawer', \"s'cuse\", 'alva', 'gore', 'undies', 'farthest', 'chairman', 'showing', 'part', 'toledo', 'pugilist', 'lips', 'married', 'bulked', 'fever', 'revenge', 'ignorance', 'pulls', 'reality', 'roy', 'remaining', 'appeals', 'gargoyle', 'diet', 'snapping', 'wednesday', 'superdad', 'tornado', 'lloyd:', 'ireland', 'lobster-politans', 'kill', 'specializes', 'scent', 'ugliness', 'unusually', 'fad', 'pharmaceutical', 'jump', 'flames', 'soot', 'crazy', 'moan', 'comfortable', 'pages', 'enforced', 'tropical', 'dr', 'bars', 'sniffles', 'notorious', 'freeze', \"bart'd\", 'alphabet', 'ways', 'enjoyed', 'mcclure', 'chub', 'indicates', 'buzz', 'ladder', \"showin'\", 'releases', 'cuckoo', 'if', 'borrow', 'disappear', 'gardens', 'apu_nahasapeemapetilon:', 'manipulation', 'reason', 'st', 'espousing', 'smiles', 'darn', 'force', 'occupied', 'reporter', 'fortress', 'starving', 'quadruple-sec', 'tiny', 'waterfront', 'attach', 'options', 'bar', 'helpful', 'snake-handler', 'suffering', '||pointandcoma||', 'defiantly', 'carefully', 'foam', 'embarrassed', 'neil_gaiman:', 'cuff', 'sissy', 'barbed', 'wishes', 'apulina', 'anthony_kiedis:', 'legal', 'roller', 'coincidentally', 'liar', 'broadway', 'ninety-six', \"robbin'\", 'homeland', 'decided', 'process', 'germany', 'olive', 'tale', 'me', 'beginning', 'kyoto', 'w', 'anti-intellectualism', 'marshmallow', 'lisa', 'loaded', \"who'll\", 'seething', 'pair', 'lovelorn', 'thrilled', 'laws', '_eugene_blatz:', 'keeps', 'peabody', 'generous', 'penmanship', 'daughter', 'nahasapeemapetilon', 'and/or', 'skills', 'tender', 'what-for', 'thing:', 'insightful', 'times', \"liftin'\", 'dark', 'puff', 'index', 'mac-who', 'i-i', 'charlie:', 'adequate', 'prepared', 'greatest', 'violin', 'mug', 'diamond', 'flatly', 'edelbrock', 'suit', 'all-all-all', 'countryman', 'would', 'european', 'occupation', 'accept', 'pink', 'together', 'ear', 'yew', 'gabriel', 'britannia', 'beyond', 'illustrates', 'occurs', 'mcbain', \"stayin'\", 'jamaican', 'adrift', 'manjula_nahasapeemapetilon:', 'circus', 'recent', 'bag', 'stationery', 'floating', 'boat', 'cupid', 'thanking', 'omit', 'kidneys', 'crab', 'upn', 'spacey', 'monkeyshines', 'glum', 'we', 'relieved', 'he', 'rig', 'thirty-five', 'making', 'grey', 'shtick', 'vacation', 'lily-pond', 'hooray', 'babar', 'gruesome', 'brought', 'desire', 'snout', '||newline||', 'pretty', 'woulda', 'flash', 'makes', 'sinister', 'hourly', 'chapter', 'fumes', 'jägermeister', 'curse', 'partly', \"'em\", 'sandwich', 'twenty-six', 'unsafe', 'milks', 'leprechaun', 'stick', 'all-american', 'ohh', 'heavens', 'james', 'pusillanimous', 'enhance', 'persia', 'mither', 'cutting', 'cab', 'bump', 'drug', 'telling', 'grandkids', 'portentous', 'chip', 'foundation', 'hugh', 'eve', 'van', 'yammering', 'horrified', 'locked', 'unintelligent', 'kadlubowski', 'acquitted', 'mock', 'box', 'judges', 'safer', 'lear', 'jobless', 'sooner', 'tips', 'quero', 'investment', 'names', 'cost', 'diving', 'know', 'fausto', 'squad', 'dennis_conroy:', 'complaining', 'intense', 'mickey', 'two-thirds-empty', 'toms', 'fellow', 'cops', 'rage', 'placed', 'cars', 'quimbys:', 'reader', 'bidet', 'eating', 'shriners', 'dropped', 'first', 'earrings', 'bite', 'pawed', 'room', 'crowded', 'panicky', '_montgomery_burns:', 'belts', 'whisper', 'ad', 'sorts', \"ladies'\", 'burps', 'languages', 'fly', 'glummy', '||dott||', 'betty:', 'grind', 'column', 'panicked', 'billiard', 'double', 'arimasen', 'german', 'books', 'twice', 'hoagie', 'literary', 'king', 'dumpster', 'paints', 'larry', 'burning', 'specified', \"brockman's\", 'test-', 'proposing', 'wistful', 'tabooger', 'digging', 'marmaduke', 'upset', 'catch-phrase', \"dolph's_dad:\", 'chauffeur', 'stacey', \"buffalo's\", 'score', 'mushy', 'dishrag', 'poured', 'looting', 'gags', 'fire', 'ointment', 'listen', 'demand', 'loudly', 'missing', 'investigating', 'unfresh', 'valley', 'kidnaps', 'sale', 'tipsy', 'bless', 'loyal', 'organ', \"puttin'\", 'outrageous', 'ho', 'jam', 'solved', 'caper', 'disappeared', \"car's\", 'caricature', 'barf', 'detail', 'was', 'rom', 'celeste', \"life's\", 'village', 'listens', '/', 'single', 'counter', 'stamps', 'specific', 'zone', 'holding', 'flush-town', 'radical', 'practically', 'population', \"somebody's\", \"we've\", 'ball-sized', 'ripped', 'horns', 'commanding', 'sunk', 'poker', \"fun's\", 'care', 'tune', 'wowww', \"dog's\", 'ooo', 'flaking', 'unattended', 'donor', 'moon', 'padre', 'empty', 'son', 'drank', 'splendid', \"shouldn't\", \"she'll\", 'warmly', 'gotcha', 'hippies', 'ecru', \"monroe's\", 'whenever', 'shush', 'monday', 'labels', 'across', 'las', 'fl', 'ga', 'contemptuous', \"man's_voice:\", 'phony', \"football's\", 'take', 'mayor_joe_quimby:', 'moe_szyslak:', 'miss_lois_pennycandy:', 'hmf', 'plans', 'vincent', 'measure', 'step', 'charlie', 'reckless', \"bart's\", 'jets', 'ruin', 'kang:', 'roses', 'side:', \"startin'\", 'fixed', \"'n'\", 'polygon', 'cutest', 'yourselves', 'someday', 'none', 'flash-fry', 'ew', 'busted', 'grunts', 'code', 'facebook', 'expecting', \"he'll\", 'extremely', 'sits', 'abandon', 'moustache', 'ninety-nine', 'charter', 'permanent', 'windowshade', 'resolution', 'tee', 'trust', 'depressing', 'meatpies', 'selective', 'funniest', \"department's\", 'label', 'it', 'kick-ass', 'wikipedia', 'chuckle', 'bret', 'ho-ly', 'phasing', 'car:', 'blown', 'show-off', 'jubilation', 'poison', 'locklear', 'taxi', 'surprised', 'missed', 'mathis', \"i-i'm\", 'generally', \"wallet's\", \"he's\", 'sanitation', 'appealing', \"y'know\", 'eventually', 'encouraged', 'endorsed', 'sleeping', 'sharity', 'soaked', 'halvsies', 'unjustly', 'timbuk-tee', 'tv-station_announcer:', \"ya'\", 'seven', \"sayin'\", 'yee-ha', 'closing', 'professional', 'corkscrews', 'justify', 'crowds', 'supermodel', 'fox_mulder:', 'du', 'misconstrue', 'his', 'talked', 'moe', 'thawing', 'nominated', 'warn', 'presses', 'rewound', 'sec_agent_#1:', 'enthusiasm', 'she-pu', 'boo', 'mansions', \"hasn't\", 'sudoku', 'cozies', 'crotch', 'refund', \"i've\", 'seeing', 'masks', 'hunting', 'waltz', 'lover', 'planned', 'wage', 'whip', 'appearance-altering', \"son's\", 'half-beer', 'wore', 'collateral', 'renee', 'about', 'front', \"shootin'\", 'stagehand:', 'improved', 'plaintive', 'depository', 'gun', 'puffy', 'picky', 'jewish', \"friend's\", \"comin'\", 'parenting', 'clinton', 'alibi', \"game's\", 'saget', 'spread', 'splash', 'smugglers', 'sympathizer', 'stagey', 'short_man:', 'flat', 'them', 'gay', 'storms', 'message', 'hemorrhage-amundo', \"lovers'\", 'irishman', 'cough', 'low-life', 'prohibit', 'yep', 'patriotic', 'warm_female_voice:', 'hoo', 'intoxicants', 'bill', 'terrace', 'blobbo', 'entire', '_zander:', 'giving', 'history', 'nervous', 'grants', \"cleanin'\", 'barkeeps', 'shyly', 'agh', 'lard', 'opening', 'wrestling', 'between', 'selfish', 'fault', 'monster', 'easter', \"one's\", 'wallet', 'freak', 'releasing', \"pullin'\", 'taken', 'gel', 'hardwood', 'always', 'maximum', 'devils:', 'delicately', 'outside', 'nicer', 'minister', 'choose', 'pepsi', 'surprise', 'inserts', 'hubub', 'society_matron:', 'filthy', 'assistant', 'duff_announcer:', 'poem', 'rebuilt', 'tomatoes', 'unfamiliar', 'pint', 'whatever', 'rubbed', 'gloop', 'bus', 'writers', 'tried', 'mother', 'hooked', 'alec_baldwin:', 'laughter', 'character', 'robin', \"mecca's\", 'important', 'hyper-credits', 'frenchman', 'sauce', 'looooooooooooooooooong', \"duff's\", 'vengeance', 'treasure', 'drunks', 'popular', 'watt', 'homeless', \"s'pose\", 'semi-imported', 'unison', \"should've\", 'remorseful', 'veux', 'five', 'instead', 'disgraceful', 'cliff', 'dozen', 'gregor', 'fifteen', 'lovers', 'piano', 'five-fifteen', 'crew', 'rubs', 'expense', 'trail', 'ocean', 'stores', 'eggshell', 'knew', 'sketching', 'bedridden', 'trouble', 'chunk', 'job', 'hampstead-on-cecil-cecil', 'developed', 'mice', 'marvin', 'do', 'heart', 'moans', 'linda_ronstadt:', 'kent', 'beligerent', 'whose', 'drunkening', 'prints', \"could've\", 'gheet', 'julienne', 'tracks', 'lift', 'rome', 'hidden', 'bridges', 'looser', 'murmur', 'kirk_voice_milhouse:', 'normals', 'manager', 'steampunk', 'fold', 'fighter', 'cocks', 'lisa_simpson:', 'nuclear', 'dae', 'automobiles', 'speech', 'radishes', 'sail', 'government', 'stolen', 'fistiana', 'in-ground', 'cruiser', 'kako:', 'kinderhook', 'noosey', 'miss', \"soakin's\", \"number's\", 'falcons', 'santa', 'show', 'hears', 'starters', 'knowledge', 'dan_gillick:', 'wok', 'sacajawea', 'methinks', 'xanders', 'kemi', 'pepto-bismol', 'hilarious', '_powers:', 'brief', 'politicians', 'firmly', 'compels', 'salt', 'solo', 'putty', 'outstanding', 'funny', 'liable', 'pine', \"i'd'a\", 'holds', \"soundin'\", 'jumps', 'chuckles', 'stalin', 'jimmy', 'clientele', 'arse', 'je', 'use', 'thirsty', 'vin', 'pews', 'spinning', 'pasta', 'thought', 'pee', 'decide:', 'fourteen:', 'spy', 'drinking', 'larry:', 'refill', 'friction', 'bully', 'open-casket', 'doy', 'data', 'mexicans', \"fans'll\", 'domed', 'app', 'dramatic', 'end', 'acquaintance', 'needs', 'courts', 'lushmore', 'out', 'month', 'uses', 'torn', 'past', 'kickoff', 'tow', 'post-suicide', 'rationalizing', 'gift', 'kentucky', 'enterprising', 'beauty', 'seek', 'beaumont', 'we-we-we', 'doreen', 'breaking', 'startup', 'kinds', 'weep', 'crestfallen', 'kramer', 'rolls', 'loboto-moth', 'sagely', 'danish', 'tease', 'nudge', 'woodchucks', 'democracy', 'sweeter', 'unhappy', 'send', 'thoughts', 'read', 'elmer', \"tap-pullin'\", 'sledge-hammer', 'wing', 'sixty-nine', 'who', 'buffet', 'lonely', 'begging', 'ambrose', \"stealin'\", 'skunk', \"world's\", 'dirty', 'size', 'smiling', 'dateline', 'guns', 'candidate', 'midge', 'sweet', 'letter', 'boxer', 'blissful', 'grinch', 'repeated', 'forget-me-shot', 'problems', 'ugh', 'guess', 'stickers', 'isotopes', 'peace', 'coins', 'killed', 'courteous', 'become', 'sampler', \"gentleman's\", 'mines', 'injury', 'square', 'shower', 'sign', '3', 'cutie', 'utensils', 'hour', 'other', 'nice', 'eyeballs', 'excited', 'modestly', 'endorsement', 'rickles', 'just', 'alarm', 'wally', 'moe-clone:', 'kissingher', 'writing', 'family-owned', 'equal', 'extreme', 'disdainful', 'relative', 'single-mindedness', 'faceful', 'ding-a-ding-ding-ding-ding-ding-ding', 'bachelor', 'indigenous', 'given', 'elect', 'stays', 'mocking', 'statistician', 'walther', 'said', 'pigtown', 'nick', 'clips', 'getcha', 'steel', 'playing', 'sir', 'insults', '91', 'recorded', 'suru', '10:15', 'gabriel:', 'cushions', 'ditched', 'realized', 'yoink', 'hotline', 'rump', 'sunglasses', 'girl-bart', 'honey', 'admirer', \"can't\", 'tanking', 'eh', 'separator', 'snide', 'dollars', \"dimwit's\", 'oughta', 'and:', 'old', 'hexa-', 'forehead', 'pyramid', 'reminded', 'photo', 'wad', 'cross-country', 'kegs', 'desperately', 'margarita', 'befouled', 'creme', 'smiled', 'diablo', 'braun:', 'jelly', 'am', 'pool', 'funds', 'upon', 'placing', 'ma', 'thoughtful', 'sixty', 'shoulders', 'declared', 'ironed', 'broad', 'shutting', 'charged', 'tv_husband:', 'exhibit', 'wash', 'stevie', 'cap', 'huh', \"others'\", 'furry', 'broncos', 'north', 'pure', 'gulps', 'traditions', 'savagely', 'aerosmith', 'diaper', 'future', 'belly', 'doubt', 'smoke', 'drink', 'streetlights', 'person', 'heartily', 'had', 'chinua', 'simplest', 'agreement', 'dishonor', 'correct', 'factor', 'infatuation', 'mayan', 'insecure', 'cut', 'restaurants', 'rims', 'repairman', 'driving', \"what's\", 'boozer', \"poisonin'\", \"bar's\", 'payday', 'boneheaded', 'synthesize', 'flew', 'boxing', 'arrest', 'mistakes', 'boston', 'voice', 'cheery', 'seriously', 'stinks', \"you'll\", 'troy_mcclure:', 'misfire', 'micronesian', 'noble', 'dance', 'months', 'napkins', 'conspiracy', 'heh', 'when-i-get-a-hold-of-you', 'cartoons', 'cause', 'teenage_homer:', 'drive', 'forgive', 'does', 'shall', 'conditioners', 'wantcha', \"mother's\", 'fainted', 'plastered', 'idea', 'y', 'menlo', 'hyahh', 'mint', 'court', 'dreamy', 'pile', 'melodramatic', 'newest', 'bushes', \"ain't\", 'watching', 'jer', 'regulars', 'socratic', 'gear-head', 'julep', 'sadder', 'website', 'movement', 'shipment', \"cont'd:\", 'mean', 'worked', 'title', 'h', \"don't\", 'voice_on_transmitter:', \"games'd\", 'temple', 'material', 'badges', 'the_rich_texan:', 'tape', 'page', 'hanh', 'onions', 'harvesting', 'rule', 'cigars', 'exultant', 'chief_wiggum:', 'reward', 'champ', 'boxers', 'marry', 'arrived', 'presents', 'belches', 'pizzicato', 'bottoms', 'dashes', 'sabermetrics', 'polishing', 'violations', 'betrayed', 'para', 'necessary', 'mister', 'pepper', 'taunting', 'dressing', 'voice:', 'p', 'cocking', 'crowned', 'nickels', 'pageant', 'various', 'windshield', 'i/you', 'harvey', 'mole', 'cash', 'changed', \"bettin'\", 'mall', 'rummy', 'cannoli', 'sticking', 'longest', 'whispers', 'grain', 'supposed', 'lord', 'east', 'ideal', 'bucket', 'reopen', 'la', 'trunk', 'military', 'albeit', 'keeping', '_timothy_lovejoy:', 'vote', 'forward', 'attractive_woman_#1:', 'awake', 'yello', 'rockers', 'squabbled', 'fight', \"'morning\", 'suburban', 'judgments', 'researching', 'eaters', 'sack', 'rainier_wolfcastle:', 'stab', 'snort', 'slightly', 'break', 'grenky', 'tha', 'recap:', 'door', 'eager', 'increasingly', 'shard', 'incredible', 'sick', 'confidentially', 'awww', 'difference', 'reciting', 'marvelous', 'damn', 'lazy', 'quimby_#2:', 'cajun', 'got', 'level', 'ned', 'lots', 'junkyard', 'defeated', 'beans', 'conversion', 'deli', 'someone', 'four', 'ten', 'kids', 'lloyd', 'sings', 'gambler', 'twenty', 'hurts', 'america', 'ghouls', 'brightening', 'drivers', 'hearing', 'frazier', 'than', 'die-hard', 'teen', 'aah', 'wondered', 'pointedly', 'unlucky', 'pus-bucket', 'don', 'surprising', 'slim', 'enough', 'pitch', 'accurate', 'swallowed', 'charges', 'answers', 'cases', 'deep', 'blows', 'author', 'sky', 'tons', 'sheet', 'cares', 'joke', 'pulitzer', 'elaborate', 'slyly', \"brady's\", 'jail', 'sink', 'adult_bart:', 'shesh', 'dime', 'gibson', 'ehhhhhh', 'blurbs', 'comes', 'folks', 'ears', 'goblins', 'overstressed', 'community', 'links', 'universe', 'triangle', 'tax', 'kwik-e-mart', 'consoling', 'towed', 'wanna', 'forgiven', 'friends', 'edge', 'unhook', 'soon', 'naturally', \"santa's\", 'tired', \"starla's\", 'attractive', 'backbone', 'sports', 'pian-ee', 'knock', 'sheets', 'poplar', 'ferry', 'malfeasance', 'takes', 'swatch', 'simple', 'forbidden', 'spouses', 'treat', 'declare', 'casting', 'tremendous', 'mozzarella', 'eyeing', 'mm', 'cranberry', 'nards', 'proper', 'wheeeee', 'wordloaf', 'freedom', 'halloween', 'muertos', 'prettiest', 'appear', 'sympathetic', 'nasa', 'state', 'slot', 'full-bodied', 'oddest', 'test-lady', 'chubby', 'koholic', 'matter', 'astonishment', 'pit', 'sincere', 'cheesecake', 'lodge', 'cocoa', 'dregs', 'blinds', 'life-sized', 'underwear', 'joking', 'specialists', 'amused', 'inherent', 'last', 'driver', \"plaster's\", 'cooker', 'humiliation', 'united', 'explaining', 'crowd', 'rub-a-dub', 'exasperated', 'vampire', \"we'd\", 'thumb', 'spirit', 'freed', 'resenting', 'enthused', 'patty', 'sucking', 'truck', 'sneering', 'issues', 'moving', 'soul', 'lobster', 'die', 'small', 'part-time', 'for', 'amends', 'herself', 'money', 'news', 'crayon', 'sitar', 'grumbling', \"lisa's\", 'consider', 'buying', 'exception:', 'along', 'assassination', 'sweat', 'meeting', 'next', 'stamp', \"yesterday's\", 'barney-shaped_form:', \"pressure's\", \"s'okay\", 'bible', 'nature', 'kissing', 'reasons', \"tramp's\", 'rev', 'wrap', 'doors', 'homer_doubles:', \"wonderin'\", \"kiddin'\", 'blinded', 'crippling', 'joe', 'fontaine', 'may', 'har', 'twelve-step', 'eyeball', 'close', 'admit', 'blamed', 'glitz', 'ass', 'politics', 'wishing', 'shifty', \"idea's\", 'plastic', 'prove', 'online', 'karaoke', 'sob', 'sight-unseen', 'vanities', 'weirded-out', 'bulletin', 'pope', 'thinks', 'outta', 'church', 'homie', 'rip-off', 'mumble', \"mopin'\", 'park', 'canyoner-oooo', 'reminds', 'sugar-free', 'repeating', 'pickle', 'attempting', 'traitors', 'lady-free', 'embarrassing', \"duelin'\", \"o'\", 'public', 'comforting', 'aboard', 'fund', 'cigarette', 'warren', 'scrutinizes', 'harrowing', 'with', 'dollface', 'shaking', 'gosh', 'tries', 'holy', 'sees', 'up-bup-bup', 'crumble', 'laney_fontaine:', 'usual', 'golf', 'older', 'sobriety', 'holiday', 'carb', 'f-l-a-n-r-d-s', 'satisfied', 'terror', 'experience', 'brusque', 'large', 'alive', 'andy', 'susie-q', 'municipal', 'mellow', 'since', 'excavating', 'real', 'pointy', 'fills', 'unavailable', 'grace', 'booth', 'nauseous', 'paste', \"weren't\", 'disapproving', 'widow', 'contemporary', 'annus', 'kissed', 'accident', 'prank', 'though', 'fbi', 'sober', 'clearly', 'hugh:', 'mostrar', 'frog', 'worried', 'considering', 'sympathy', 'whistles', 'harder', 'quality', 'smitty:', 'hang', 'yogurt', 'works', 'social', 'image', 'sell', 'boisterous', 'nbc', 'cakes', 'western', 'spending', 'crooks', \"father's\", 'admiring', 'tickets', 'closer', 'go', 'getaway', 'groveling', 'disappointing', 'smokes', 'supports', 'goal', 'knocked', 'runners', 'distraught', 'intoxicated', 'chin', 'faulkner', 'thrust', 'grandé', 'slogan', 'sharing', 'knows', 'koi', \"queen's\", 'laugh', 'girls', 'card', 'greystash', 'ze-ro', 'pretends', 'civilization', 'gently', 'madison', 'darts', '3rd_voice:', 'butter', 'nordiques', \"year's\", 'caveman', 'named', 'studied', 'rods', 'clincher', 'snail', 'rap', 'twenty-nine', 'following', 'eddie:', 'tv_wife:', 'principles', 'in', 'knife', \"floatin'\", 'spelling', 'able', 'fresh', 'career', 'clothespins:', 'crack', 'fury', 'waking-up', 'earlier', 'direction', 'sweaty', 'racially-diverse', 'musses', 'airport', \"burnin'\", 'compliment', 'partners', 'williams', 'wire', 'nibble', 'helps', 'prince', 'item', 'crystal', \"scammin'\", 'impending', \"that'd\", 'heaving', 'offended', 'purveyor', 'different', 'pointless', 'floated', 'sponge', 'debonair', 'africanized', 'check', 'souvenir', 'kirk_van_houten:', 'stan', 'sentimonies', 'cuz', 'oh', 'killarney', 'knees', 'device', 'lock', 'kindly', 'local', 'caholic', 'homer_', 'riding', \"tester's\", 'babe', 'rumaki', 'edna', 'convenient', 'fighting', 'lotta', 'theatah', 'highway', 'awareness', \"'ere\", 'puts', 'share', 'vomit', 'jumping', 'bottle', 'hah', \"plank's\", 'darkness', 'sketch', 'shred', 'fellas', 'acronyms', 'palmerston', 'serious', 'obese', 'boxcar', 'peach', 'kidney', 'pleasure', 'contest', 'zeal', 'compadre', 'spellbinding', 'legoland', 'phase', 'plus', 'forty-nine', 'sobbing', 'french', 'cheerleaders:', 'officials', \"livin'\", 'cab_driver:', 'practice', 'tie', 'spotting', 'wants', 'bear', 'encouraging', 'vegas', 'wizard', 'honest', 'aggravazes', 'buds', 'wears', 'macgregor', 'hand', 'meyerhof', 'fluoroscope', 'frat', 'finally', 'cappuccino', 'night', 'reporter:', 'hole', 'attractive_woman_#2:', 'compromise:', 'muscle', 'dizer', 'wienerschnitzel', 'beating', 'moesy', \"i'm\", 'owned', 'pep', 'edna_krabappel-flanders:', 'young', 'looks', 'lurks', 'bragging', 'chips', 'soup', 'congratulations', 'abercrombie', 'el', 'puzzled', 'load', 'dictator', 'discriminate', 'shock', 'starla', 'wild', 'foot', 'taxes', 'yellow', 'si-lent', 'afraid', 'helicopter', 'dang', 'trip', 'normal', 'gal', \"fryer's\", 'bits', 'carpet', 'jovial', 'bothered', 'heroism', 'co-sign', 'seats', 'deacon', \"collector's\", 'packets', 'orifice', 'shill', 'lately', 'b', 'other_player:', 'pronto', 'point', 'around', 'imaginary', 'smell', \"stabbin'\", 'sales', 'chapel', 'leg', \"it'll\", 'tummies', 'toward', 'neighboreeno', 'scram', 'strokkur', 'clean', 'fortune', 'okay', 'chair', 'noise', 'appendectomy', 'lose', 'signed', 'rug', 'managed', 'charge', 'warning', 'pathetic', 'short', 'died', 'dealt', 'slurps', \"maggie's\", 'abcs', 'convinced', 'vigilante', 'rosey', 'corporation', 'playoff', 'liquor', 'jukebox', 'one', 'richer', 'bought', 'twentieth', 'brunswick', 'sub-monkeys', 'sweetly', 'voodoo', \"guy's\", 'maxed', 'whaddaya', 'popping', 'someplace', \"dad's\", 'newly-published', 'pretzel', 'fink', 'divorced', 'bloodiest', 'lewis', 'clammy', \"coaster's\", 'covering', 'notch', 'cheer', \"boy's\", 'fraud', \"wouldn't-a\", 'ralphie', 'fumigated', 'flophouse', 'blade', 'perking', 'wrong', 'zoomed', 'singing', 'geysir', 'innocent', 'address', 'aside', 'ken:', 'possibly', 'contemplates', 'cool', 'sloppy', 'motto', 'porn', 'perfect', 'e-z', 'pushing', 'stingy', 'honored', 'bouquet', 'dignified', 'grampa', 'agency', 'astronaut', 'program', 'exited', 'priority', 'words', 'three-man', 'crony', 'flaming', \"b-52's:\", 'deeper', 'partner', 'andalay', 'duke', 'often', 'way:', 'soothing', 'anniversary', 'stars', 'cop', 'stalking', \"kearney's_dad:\", 'begins', 'derek', 'hunger', 'jacks', 'dennis_kucinich:', 'woman', 'dracula', 'brother', 'eggs', 'city', 'tearfully', 'chipper', 'nasty', 'pretend', 'army', 'channel', 'shrugging', 'runaway', 'started', 'grabs', 'figures', 'black', 'focus', 'thirty-thousand', 'ron_howard:', 'themselves', 'grieving', 'bid', 'serve', 'fourth', 'reunion', 'tall', 'hard', 'daniel', 'cletus_spuckler:', 'harv:', 'vampires', 'kansas', 'stairs', 'compliments', 'deliberately', 'jewelry', 'securities', 'pack', 'log', 'rings', 'juan', 'dumbass', 'birth', 'asses', 'courage', 'nevada', 'colonel:', 'feedbag', 'least', 'pop', 'an', 'joined', 'oooo', 'hibachi', 'chained', 'they', 'achebe', 'stocking', 'despite', 'macbeth', 'frink', 'valuable', 'darjeeling', '14', 'undated', 'approval', 'hostile', 'bye', 'completely', 'flashbacks', 'ohhhh', 'sucker', 'donate', 'advertise', 'tourist', 'apply', 'o', 'rugged', 'buddy', 'gasp', 'lou', \"nick's\", 'talking', 'young_barfly:', 'loneliness', 'appreciated', 'favorite', 'poke', 'plenty', 'hike', 'stu', 'lot', 'polls', \"you've\", \"buyin'\", 'riveting', 'woozy', 'pushes', 'drown', 'focused', 'oopsie', 'lenses', 'spreads', 'behavior', \"show's\", 'finishing', 'boring', 'habitrail', 'sweetest', 'punching', 'reviews', 'brassiest', 'lend', 'pays', 'aghast', 'microwave', 'hi', 'urine', 'astronauts', 'samples', 'damned', 'beer-dorf', 'issuing', 'safely', 'afterglow', 'count', 'professor', 'shrugs', 'aunt', 'larson', 'treats', 'sucks', 'famous', 'few', 'insist', 'under', \"couldn't\", \"getting'\", 'whispered', 'whether', 'candy', 'heading', 'source', 'dean', 'hellhole', 'krabappel', 'wheel', 'guide', 'poster', 'examines', 'killjoy', 'dipping', 'ends', \"isn't\", 'owner', 'artist', 'voyager', 'subject', 'though:', 'planted', 'the', 'butterball', 'x-men', 'grease', 'updated', 'expose', 'who-o-oa', 'girl', \"'pu\", \"everyone's\", 'thoughtless', 'broken', 'monorails', 'virile', 'true', 'swelling', 'sneak', 'fantastic', 'lawyer', 'scout', 'quietly', 'cleaning', 'sending', 'tuborg', 'coherent', 'punishment', 'celebrities', 'presidential', 'playful', 'fires', 'thighs', 'gus', 'otherwise', 'prices', 'lotsa', 'disguised', 'jerky', 'super', 'occurrence', 'luck', 'hollywood', 'frontrunner', 'schmoe', \"cheerin'\", 'youse', 'selling', 'star', 'inflated', 'presumir', 'novel', 'smoothly', 'cursed', 'bumpy-like', 'wigs', 'flying', \"mtv's\", 'gary_chalmers:', 'moolah-stealing', 'doctor', 'monkey', 'huhza', 'tomorrow', 'wally:', 'righ', 'six-barrel', 'intakes', 'blur', 'shhh', 'maya', 'feast', 'mystery', 'man', 'rough', 'helpless', \"tv's\", 'wenceslas', 'sneaky', 'book_club_member:', 'sternly', 'danny', 'handwriting', 'nonsense', 'homer_simpson:', 'uncreeped-out', 'massage', 'fix', 'yak', 'christian', 'yesterday', 'determined', 'poet', 'dirt', 'toasting', 'contractors', 'bring', 'pipes', '6', 'groin', 'cents', 'strictly', 'ziff', 'rhyme', 'must', 'captain:', 'alma', 'beneath', 'sport', 'whatchamacallit', 'numeral', 'wanted', 'ha-ha', 'burn', 'underpants', 'nightmare', 'belong', 'my', 'chug', 'video', 'lenny', ':', \"cat's\", 's', 'female_inspector:', 'drapes', 'else', 'word', 'executive', '_julius_hibbert:', 'compare', 'please/', 'whaaa', 'donuts', 'shoot', 'upsetting', 'pay', 'stunned', 'commit', '2nd_voice_on_transmitter:', 'moved', 'thousand-year', 'exchanged', 'dreamily', 'hours', 'heals', 'hold', 'package', 'enemy', 'mmmmm', 'hospital', 'consciousness', 'jolly', 'species', 'sheepish', 'involving', 'smurfs', '50-60', \"homer'll\", 'reluctant', 'actress', 'bathing', 'manjula', 'ivy-covered', 'chum', \"sat's\", 'employment', 'sideshow_bob:', 'shirt', 'awkwardly', 'mugs', \"men's\", 'motel', 'gunter', 'saucy', 'triple-sec', 'morose', 'swishkabobs', 'brave', \"time's\", '50%', '530', 'fun', 'na', 'transylvania', 'gimmicks', \"valentine's\", 'forty-five', 'champignons', 'environment', 'furiously', 'farewell', 'breathless', 'available', 'spoon', '$42', 'working', 'sorry', 'fleabag', 'hop', 'associate', 'center', 'bret:', 'temporarily', 'flexible', 'glass', 'flourish', 'guinea', 'charity', 'logos', \"cupid's\", 'heavyset', 'enabling', 'isle', 'unexplained', 'watch', 'jacksons', 'putting', 'friendly', 'handshake', 'luckiest', 'need', 'rip', 'anger', 'eco-fraud', 'alfalfa', 'kind', 'unforgettable', 'cheerier', 'appropriate', 'laughs', 'takeaway', 'having', 'bulldozing', 'then:', 'shuts', 'greatly', 'voted', 'luv', 'prizefighters', 'cricket', 'law', 'connection', 'cosmetics', 'emphasis', 'are', 'animals', \"mo'\", 'honeys', \"washin'\", 'bites', 'rock', 'disillusioned', 'fuhgetaboutit', \"writin'\", 'nantucket', \"changin'\", 'copy', 'lying', 'powers', 'ragtime', 'mad', 'balloon', 'africa', 'mountain', 'detective', 'narrator:', 'furniture', 'hoax', 'radioactive', 'insured', 'goo', \"what'll\", 'senators:', \"o'problem\", 'early', 'announcer:', 'düff', 'forty', 'partially', 'sudden', 'cheapskates', 'directions', 'elizabeth', 'toilet', 'throats', 'homer', 'breakdown', 'wonderful', 'reluctantly', \"tellin'\", 'entering', 'conclusions', 'sustain', 'jack_larson:', \"calf's\", 'delts', 'smells', 'lifetime', 'computer', 'service', \"squeezin'\", 'wrestle', 'arabs', 'british', 'watered-down', 'brag', 'umm', 'patrons:', 'los', 'ones', 'befriend', 'adopted', 'tokens', 'dryer', 'wobble', 'lottery', 'cooler', 'lucinda', 'fustigate', 'quite', 'bit', 'fastest', 'yet', 'saying', 'pause', 'sticker', 'gallon', 'november', 'teacup', 'crummy', 'feisty', 'nuts', 'safe', 'stadium', 'thorough', 'reasonable', 'milk', 'effects', 'hottest', 'using', 'plane', 'insensitive', 'intention', 'darkest', 'choked', 'every', 'which', 'repay', 'rafters', 'whup', 'opportunity', \"she's\", 'super-genius', 'rich', 'modest', 'maitre', 'ooh', 'squirrel', 'seymour_skinner:', 'gold', 'nigel_bakerbutcher:', 'libraries', 'stretches', 'muslim', 'forgot', 'phrase', 'ago', 'handsome', 'carnival', 'brains', 'roz', 'outlive', 'mouse', 'louse', 'conclude', 'annie', 'xx', 'mags', 'chosen', 'ominous', 'proof', 'invisible', 'student', 'sickened', 'surgeonnn', 'hat', 'homesick', 'each', 'turkey', 'chic', 'wife-swapping', 'amount', 'shutup', 'asked', 'lovejoy', 'sister-in-law', 'winks', 'jukebox_record:', 'of', 'savings', 'express', 'minimum', 'sen', 'fritz:', 'how', 'sing-song', 'formico', 'installed', 'faith', 'dreary', 'explanation', 'fat_tony:', 'reaction', 'birthday', 'suspended', \"battin'\", 'lurleen', 'hug', 'magic', 'alcohol', 'grateful', 'vicious', 'costume', 'bar_rag:', 'statesmanlike', 'cards', 'recommend', 'louisiana', 'plotz', 'ran', 'unbelievable', \"o'reilly\", 'sugar', 'stats', 'stay-puft', 'twenty-four', 'fantasy', 'license', 'morning', 'man_with_crazy_beard:', 'morlocks', 'ease', 'keep', 'heaven', 'trick', 'world-class', 'appalled', 'starting', \"moe's_thoughts:\", 'fit', 'men:', 'achem', 'grrrreetings', 'enlightened', 'wow', \"beer's\", 'sweater', 'eddie', 'dogs', 'tapping', 'luxury', 'de-scramble', 'hairs', 'deliberate', 'extinguishers', 'foil', 'duffman:', 'bashir', 'a', 'heliotrope', 'patrons', 'elephants', 'tenuous', 'dinner', 'culkin', 'brothers', 'gasps', 'wooden', 'lise:', 'spilled', \"phone's\", 'domestic', 'fair', 'buy', 'procedure', 'barflies:', 'suave', 'tolerance', 'burp', 'cheering', 'this', 'aquafresh', 'clenched', 'doing', 'exciting', 'wh', 'twerpy', 'aisle', \"neighbor's\", 'choking', 'gals', 'unable', 'whale', 'casual', 'presentable', 'officer', 'ohmygod', 'gunk', 'nineteen', 'pockets', 'played', 'squashing', 'tradition', 'soaps', 'road', 'geyser', 'talk', 'naively', 'coward', 'slapped', 'weight', 'night-crawlers', 'chuck', 'known', 'rafter', 'beings', 'miserable', 'booking', 'increased', 'shoes', 'fella', 'maggie', 'jerry', 'yeah', 'eminence', 'wiggle-frowns', 'wise', 'life:', 'rusty', 'sinkhole', 'dull', 'feminist', 'philip', 'faiths', '1895', 'dangerous', 'beach', 'audience', 'tasimeter', 'brainiac', 'ugly', 'invited', 'frescas', 'badmouths', 'jerking', 'little_man:', 'ummmmmmmmm', 'what', 'wagering', \"homer's\", 'halfway', 'evening', 'hygienically', 'poetry', 'neighborhood', 'dammit', 'hundreds', 'passed', 'anarchy', 'sec_agent_#2:', 'act', 'batmobile', 'pleasant', 'dress', 'sneeze', 'ate', 'option', 'soir', 'yours', 'anyhoo', 'cage', 'joy', 'victorious', \"someone's\", 'schizophrenia', 'elocution', 'beloved', 'cock', 'aims', 'sacrifice', 'getting', 'billboard', 'brain', 'low-blow', 'cavern', 'dessert', 'director', 'plain', 'stood', 'look', 'priest', 'slays', 'mckinley', 'trenchant', \"thing's\", 'wipe', 'klown', 'chew', 'toy', 'alternative', 'eyes', 'delicious', 'gees', \"d'\", 'inside', 'cleveland', 'jockey', \"'cept\", 'blaze', 'solves', 'represent', 'quotes', 'hillbillies', 'dee-fense', 'you-need-man', 'movies', 'graves', \"donatin'\", 'detective_homer_simpson:', 'dank', \"what're\", 'rub', 'snotty', 'high', 'workers', 'blood', 'slit', 'new', 'products', 'third', 'built', 'duel', 'admitting', 'grin', 'bono', 'gesture', 'viva', 'shelbyville', 'cheaper', 'pall', 'harm', 'refresh', 'acceptance', 'relax', 'chick', 'calling', \"this'll\", \"tonight's\", 'paint', 'anonymous', 'thoughtfully', \"there's\", 'rasputin', 'lighter', 'tsking', 'i-i-i', 'iran', 'here-here-here', 'could', 'hardhat', 'system', 'experienced', 'bourbon', 'bleak', 'fabulous', 'nameless', 'bail', 'sexy', 'perch', 'be', 'finished', 'ehhh', 'ons', 'midnight', 'hail', 'incognito', 'balls', 'reflected', 'switched', 'salvador', 'bird', 'jesus', 'klingon', 'maya:', 'free', 'celebration', 'hibbert', 'jeers', 'hotenhoffer', 'simpsons', 'snap', 'wars', 'wacky', '||comma||', 'nigerian', 'dies', 'alfred', 'total', \"tatum'll\", 'wipes', 'squeeze', 'sotto', 'cologne', 'sold', 'protesting', 'arrested:', 'imported-sounding', '7g', 'dungeon', 'upgrade', 'dumbest', 'murdered', 'boyhood', 'snake_jailbird:', 'cousin', 'mural', 'possessions', 'guard', 'decadent', 'psst', 'whatcha', 'sideshow_mel:', 'settles', 'director:', 'fast-food', 'shoe', 'beep', 'bow', 'movie', 'lease', 'seminar', \"moe's\", 'chuckling', 'idiot', 'troy', 'value', 'horror', 'layer', 'pond', 'replaced', 'limited', 'change', 'committee', 'dateline:', 'run', 'eye', 'attitude', 'notice', 'ye', 'hammy', 'wha', 'gin-slingers', \"snappin'\", 'paying', 'junebug', 'operation', 'fifth', 'offense', 'occupancy', 'indeed', 'new_health_inspector:', 'nursemaid', 'low', 'soaking', 'peanuts', 'favor', 'lied', 'nothing', 'habit', 'mine', 'mumbling', 'kemi:', 'jar', 'party', 'toss', 'blend', 'ebullient', 'rolling', 'afternoon', 'anyone', 'expect', 'yoo', 'great', 'milhouse', 'stinger', \"blowin'\", 'trapping', 'gestated', 'whatchacallit', 'grocery', 'ever', 'half-back', 'unkempt', 'fuzzlepitch', 'cotton', 'so-ng', 'comic', 'reserved', 'jig', 'maher', 'walking', 'till', 'wind', \"'now\", 'pilsner-pusher', 'machine', 'designer', 'oils', 'carve', 'nickel', 'cheryl', 'buddies', \"nothin's\", 'floor', 'unsanitary', 'sec', 'root', 'spite', 'goes', 'fights', 'droning', 'prayer', \"speakin'\", 'pouring', 'precious', 'mostly', 'stage', 'bigger', 'disgrace', 'roll', 'read:', 'lemme', 'passion', 'media', 'portfolium', 'delightful', 'mulder', 'crime', 'calls', 'trade', 'queen', 'store-bought', 'eternity', 'ruby-studded', 'ugliest', 'goodbye', 'lipo', 'plug', 'nine', 'kool', 'pussycat', 'win', 'fingers', 'fruit', 'muhammad', 'department', 'apart', 'pipe', 'ginger', 'banned', 'firing', 'hangout', 'hunter', 'guiltily', 'mason', 'territorial', 'ceremony', 'runs', 'said:', 'shares', 'barbara', 'burglary', 'she', 'wishful', 'lurleen_lumpkin:', 'training', 'sadly', \"what'sa\", 'considers', 'musta', 'bart_simpson:', 'healthier', \"breakin'\", 'dumb', 'coffee', 'reaching', 'touches', 'administration', 'simultaneous', 'diapers', 'confidential', \"doin'\", 'kermit', 'published', 'soap', 'roach', 'creature', 'cake', 'knock-up', 'eyesore', 'fiction', 'shot', 'rather', 'during', 'yuh-huh', 'conference', 'because', 'damage', 'son-of-a', 'beats', \"carl's\", 'stinky', 'come', 'couch', 'grimly', 'pain', 'threatening', 'carll', 'hooch', 'reach', 'agent_miller:', 'two', 'capitalists', 'theory', 'confidence', \"fendin'\", \"wasn't\", 'fictional', 'onto', 'spender', 'slip', 'brain-switching', 'japanese', 'proud', 'blossoming', 'snake', 'stares', 'proposition', 'medieval', 'learned', 'veteran', 'rainbows', 'including', 'stones', 'brother-in-law', 'ultimate', 'wife', 'space', 'bobo', 'twins', \"doctor's\", 'examples', 'hair', 'boys', 'tap', 'realize', 'jane', \"betsy'll\", 'fools', 'brandy', 'romance', 'rapidly', 'dressed', 'leonard', 'railroads', 'most:', 'occurred', 'white_rabbit:', 'risqué', 'david', '||qutes||', \"man's\", 'husband', 'teriyaki', 'eighty-six', 'miracle', 'sector', 'badge', 'apartment', 'dealie', 'switch', 'phlegm', 'musical', 'highest', 'ducked', 'cell-ee', 'gimmick', \"people's\", 'talk-sings', 'chunky', 'noose', 'lead', 'mic', 'zinged', 'cat', 'dry', 'windex', 'frink-y', 'fortensky', 'sunday', 'law-abiding', 'authorized', 'travel', 'tapered', 'backing', 'rats', 'dinks', 'knives', 'justice', 'potatoes', 'craphole', 'cameras', \"bartender's\", 'easy', 'rope', 'tire', 'tree', 'showered', 'watched', 'flack', 'ronstadt', 'is', 'taking', 'princess', \"city's\", 're-al', 'wonder', 'arise', 'shows', 'challenge', 'absolut', 'result', 'support', 'screw', 'pretending', 'branding', 'chill', 'haw', 'company', \"g'ahead\", 'old_jewish_man:', 'slow', 'dan', 'collette:', 'cell', 'quarter', 'rules', 'voicemail', 'gunter:', 'anybody', 'blow', 'entertainer', 'uncle', 'eightball', 'passes', 'lowers', 'such', 'picked', 'complete', 'health', 'portuguese', 'smallest', 'ya', 'nurse', 'kisser', 'headhunters', 'grab', 'glamour', 'cleaned', 'patty_bouvier:', 'killer', 'sexual', 'taught', 'queer', \"meanin'\", 'charming', 'insulted', 'exit', 'bowled', 'tigers', 'helped', 'skeptical', 'malabar', 'barber', 'reentering', 'pick', 'saga', 'round', 'near', 'dejected', 'gut', 'swear', 'photos', 'dearest', 'angel', 'excitement', 'seat', 'pancakes', 'boxcars', 'week', 'bono:', 'intelligent', 'ambrosia', 'renders', 'corpses', 'virtual', 'weird', 'colossal', 'without', 'committing', 'emotion', 'stirrers', 'neanderthal', 'iddilies', \"thinkin'\", 'being', 'god', 'hiding', 'stuff', 'love-matic', 'forgotten', 'wasted', 'combine', 'mill', 'recall', \"'til\", 'churchill', 'roof', 'speaking', \"fishin'\", 'find', 'buffalo', 'accidents', 'ticket', 'navy', 'granted', 'argue', 'trench', 'botanical', 'informant', 'joey', 'vacuum', 'helllp', 'myself', 'kennedy', 'feeling', \"nixon's\", 'baloney', 'ha', 'victim', 'muttering', \"neat's-foot\", 'hustle', \"now's\", 'write', 'huddle', 'relationship', 'wade_boggs:', \"how're\", 'nachos', 'ahh', 'trash', 'attend', 'kay', 'togetherness', 'thousands', 'present', 'edner', 'wear', 'classy', 'syrup', 'splattered', 'fox', 'pumping', 'seconds', 'scum', \"enjoyin'\", \"fine-lookin'\", 'bull', 'shotgun', 't-shirt', 'rounds', 'statues', 'gone', 'alcoholism', 'menacing', 'hems', 'birthplace', 'percent', 'cold', 'maintenance', 'mount', 'perón', 'fustigation', 'grunt', 'gentles', \"knockin'\", 'bumped', 'touchdown', 'smuggled', 'pressure', 'negative', \"they've\", 'treehouse', 'open', 'sang', 'whoa-ho', 'slurred', 'patting', 'royal', 'dyspeptic', \"here's\", 'irish', 'wrecking', 'criminal', 'gumbel', 'fool', 'rat', 'bonding', 'eleven', 'cruel', \"seein'\", 'awe', 'forgets', 'watered', 'k', 'estranged', 'father', 'discuss', 'raising', 'insurance', 'michelin', 'remembered', 'faded', 'creeps', 'gang', 'stillwater:', 'len-ny', 'swine', 'grains', 'dramatically', 'moonlight', 'hooky', 'bowl', '1979', 'depression', 'glove', 'power', 'fresco', 'mmmm', 'lungs', 'ho-la', 'profiling', 'wave', 'blimp', 'payments', \"'\", 'stepped', 'pantsless', 'enjoys', 'concentrate', 'sleigh-horses', 'closed', 'thirty', 'regret', \"i-i'll\", 'higher', 'gonna', 'burt', 'knowingly', 'bathtub', 'maude', 'womb', 'endorse', \"lenny's\", 'stayed', 'stand', 'place', 'toxins', 'bottles', 'homunculus', 'jeff_gordon:', 'expert', 'turlet', 'whining', 'naval', 'hoped', 'ringing', 'ron', 'seas', 'stripes', 'improv', 'same', 'richard:', 'generosity', 'texas', 'handoff', \"elmo's\", 'idealistic', 'watashi', 'graveyard', 'tow-talitarian', 'bears', 'pinball', 'renovations', 'warmth', 'today', 'barn', 'bleacher', 'goods', 'class', 'bumblebee_man:', 'tom', 'evergreen', 'indignant', 'michael_stipe:', 'pig', 'gift:', 'knuckles', 'clandestine', \"workin'\", 'text', 'x', 'allegiance', 'mention', \"costume's\", 'bees', 'singer', 'through', 'writer:', 'frankly', 'volunteer', 'thought_bubble_homer:', 'glen', 'realizing', 'affection', 'jailbird', 'tanked-up', 'then', 'hateful', 'predecessor', 'mull', 'grub', 'oww', 'language', 'peter', 'reliable', 'wait', 'dingy', 'california', 'duffed', 'windelle', 'water', 'peter_buck:', 'f', 'bubbles-in-my-nose-y', 'snow', 'caught', 'passports', 'busy', 'stole', 'shoulda', 'life-threatening', 'difficult', 'mafia', 'choked-up', \"kids'\", 'briefly', 'connor', 'bucks', 'ned_flanders:', 'germs', 'coney', 'crowd:', 'disappointment', 'sea', 'upbeat', 'brings', 'gas', 'iranian', 'meaningful', 'stretch', 'against', 'bush', 'sideshow', 'pained', 'macaulay', 'teenage', 'hammock', 'both', 'newsweek', \"c'mere\", 'bookie', 'alien', 'return', \"edna's\", 'itself', 'orders', 'griffith', 'wholeheartedly', 'provide', 'second', 'customer', 'loan', 'problem', 'mail', 'suppose', \"who's\", 'guessing', 'nuked', 'liser', 'thought_bubble_lenny:', 'easygoing', 'awwww', 'remember', 'greedy', 'talkative', \"summer's\", 'tofu', 'presto:', 'football', 'leathery', 'parasol', 'grammy', 'credit', 'italian', 'think', 'regretful', 'goodnight', 'groan', 'lighting', 'us', 'renee:', 'chumbawamba', 'optimistic', 'answer', 'stir', 'occasional', 'eu', 'something', 'hurt', 'impatient', 'causes', \"we're\", 'pride', 'brown', 'innocence', 'madman', 'stupidly', \"i'll\", 'drains', 'alcoholic', 'managing', 'loss', 'snitch', 'temper', 'like', 'coal', 'puzzle', 'sat', \"nothin'\", 'ungrateful', 'bubble', 'collapse', 'bottomless', 'not', 'office', 'othello', 'wheels', 'literature', 'freshened', 'robbers', 'table', 'kitchen', 'script', 'cola', 'rat-like', 'scarf', '70', 'email', 'boxing_announcer:', 'mcstagger', 'blubberino', 'basement', \"grandmother's\", 'discussing', 'typing', 'absolutely', \"school's\", 'jobs', 'disgusted', 'george', 'tying', 'elite', 'a-a-b-b-a', 'haplessly', 'period', 'carny:', 'opens', 'bullet-proof', 'corporate', 'easily', 'home', 'coma', 'thirteen', 'subscriptions', 'funeral', \"where's\", 'salary', 'sometimes', 'hear', 'spanish', 'tony', 'yards', 'problemo', 'handle', 'billy_the_kid:', 'annoying', 'brow', 'marched', 'shout', 'shocked', \"hobo's\", \"'er\", 'squirrels', 'madonna', 'perverted', 'lobster-based', 'tastes', 'moments', 'shark', 'reading', 'butts', 'moonshine', 'routine', 'left', 'oooh', 'half', 'syndicate', 'bike', 'sigh', 'turned', 'combines', 'bedbugs', 'pizza', 'beaumarchais', 'sleep', 'full', 'raging', 'when', 'struggling', 'aged', 'badmouth', \"ridin'\", \"homer's_brain:\", 'horrible', 'relaxing', 'zero', 'pledge', 'ballclub', 'foodie', 'anti-crime', 'bleeding', 'that', 'silence', 'instantly', 'chilly', 'speak', 'daddy', 'camp', 'selection', 'bold', 'choices', \"how's\", 'clothespins', 'full-time', 'civic', 'ollie', 'longer', 'warranty', 'groans', 'afloat', 'parents', 'businessman_#2:', 'loved', 'race', 'limits', 'tail', 'typed', 'falling', 'sight', 'food', 'banquo', 'country-fried', 'albert', 'expensive', 'little', 'pull', 'artie', 'rain', 'complaint', 'schemes', 'based', 'blob', \"high-falutin'\", \"askin'\", 'oh-so-sophisticated', 'youth', \"hawkin'\", 'oak', 'reptile', 'sense', 'survive', 'mr', 'losing', 'awfully', 'vulgar', 'wound', 'hafta', 'giant', 'south', 'hall', 'scooter', 'shaker', 'carlson', 'tell', 'audience:', 'sesame', 'uglier', \"marge's\", 'record', 'grow', 'manage', 'meditative', 'random', 'lady', 'reed', 'yourself', 'ninety-seven', 'live', 'ow', 'temp', 'hmmm', 'weak', 'face-macer', 'offer', 'simon', 'story', 'uh', 'panties', 'alright', 'amiable', 'more', 'nearly', 'powered', 'strips', 'inches', 'play', 'skydiving', 'recently', 'cockroaches', 'skins', \"doesn't\", 'other_book_club_member:', 'nfl_narrator:', 'delivery', 'nobody', 'biggest', 'hero-phobia', 'simp-sonnnn', 'rancid', 'nail', 'heh-heh', 'cherry', 'horses', 'strap', 'compete', 'finding', 'happiness', 'mccarthy', 'straight', 'dumbbell', 'tabs', 'attached', 'away', 'medical', 'sex', 'reading:', 'kicks', 'sisters', 'pre-recorded', 'items', 'janette', 'schnapps', 'chipped', \"rasputin's\", 'boy', 'penny', 'needy', 'multi-national', 'fire_inspector:', 'accepting', 'life-partner', 'give', 'lookalikes', 'alpha-crow', 'versus', 'contented', 'annual', 'holidays', 'arab_man:', 'fica', 'mix', 'dutch', 'million', 'miles', 'heatherton', \"smokin'\", 'gotten', 'touch', 'fireball', 'gasoline', 'some', 'fat_in_the_hat:', 'throws', 'man:', 'heads', 'eighty-seven', 'leaving', 'fast-paced', 'applesauce', 'frogs', 'cecil_terwilliger:', 'calm', 'your', \"something's\", 'leno', 'não', 'citizens', 'brunch', 'whoo', 'delivery_man:', \"readin'\", 'demo', 'or', 'crappy', 'peeved', 'yourse', 'symphonies', 'medicine', 'kent_brockman:', 'beer-jerks', 'physical', 'capitol', 'friday', 'distract', 'springfield', 'mortal', 'newsies', 'sitcom', 'mayor', 'crapmore', 'publishers', 'robot', 'waist', 'button', '4x4', 'play/', 'hanging', \"tab's\", 'doom', 'sixteen', 'scientific', 'ashtray', 'pub', 'rice', 'unbelievably', 'supervising', 'broken:', 'humanity', 'lachrymose', 'picnic', 'soft', 'paintings', 'scene', 'shindig', 'montrer', 'ninety-eight', 'stuck', 'tribute', 'product', 'ordered', 'k-zug', 'advice', 'addiction', 'scrape', 'mariah', 'radio', 'bedroom', 'terrifying', \"g'on\", \"talkin'\", 'rookie', 'bob', 'liability', 'wildest', 'cure', 'pointing', 'stirring', 'mouths', 'journey', 'outs', \"bein'\", 'cover', 'yup', 'child', 'dealer', 'presided', 'keys', 'happily', 'doll', 'shareholder', 'tatum', 'private', 'tones', 'steely-eyed', 'beam', 'moon-bounce', \"i'm-so-stupid\", 'moonnnnnnnn', 'fondest', 'personal', 'jubilant', 'all-star', 'permitting', 'closet', 'murderously', 'used', \"drivin'\", 'willing', 'tight', \"bo's\", 'shortcomings', 'u', 'hurting', 'bart', 'mike', 'perfected', 'grim', 'starla:', 'breathalyzer', 'cerebral', 'karaoke_machine:', 'encores', 'reactions', 'ironic', 'greetings', 'satisfaction', 'leave', 'pinchpenny', 'space-time', 'rash', 'health_inspector:', 'down', 'fifty', 'photographer', 'aidens', 'legs', 'mouth', 'pudgy', 'capuchin', 'growing', 'punches', 'quarterback', 'beers', 'extended', 'championship', 'ads', 'yee-haw', 'dame', 'held', 'hideous', 'referee', 'wolfcastle', 'moe_recording:', 'presidents', 'uneasy', 'whoops', 'moment', 'competitive', 'crow', 'pitcher', 'mrs', 'softer', \"i'unno\", 'retired', 'fletcherism', 'pickles', 'captain', 'proudly', 'absentminded', 'register', 'smelly', 'cheers', 'ride', 'painted', 'big', 'sees/', \"industry's\", 'champion', 'pigs', 'swill', 'body', 'oblivious', 'distributor', 'ails', 'forty-seven', 'visas', 'barflies', 'hated', 'corner', 'denser', 'alls', 'jay', 'explain', 'dint', 'bum:', 'teddy', 'onion', \"patrick's\", 'edison', 'shoulder', 'winning', 'gimme', 'throat', \"bladder's\", 'suspect', \"she'd\", 'cronies', '_marvin_monroe:', 'imitating', 'yelling', 'spare', 'taps', 'join', 'genius', 'hawking:', 'finger', 'destroyed', 'simpson', 'encore', 'dennis', 'traffic', 'forget-me-drinks', 'massive', 'hans:', 'hero', 'shoots', 'plow', 'scratcher', 'salad', \"wait'll\", 'telegraph', 'awesome', 'it:', 'tongue', 'sips', 'strategy', 'continued', 'tragedy', 'stewart', 'draw', 'bell', 'democrats', 'finest', 'waste', 'eighty-one', 'evasive', 'stranger:', 'nigeria', 'tank', 'prompting', 'wolverines', \"let's\", 'go-near-', 'multi-purpose', 'pursue', 'annoyed', 'grienke', 'crying', 'dory', 'even', 'prejudice', 'and', 'coat', 'deny', 'grumpy', 'ought', 'acting', 'time', 'nemo', 'bastard', 'principal', 'crank', 'joey_kramer:', 'nervously', 'deals', 'sprawl', 'composer', 'carney', 'considering:', 'refreshing', 'talkers', 'hostages', 'avec', 'poulet', 'three', 'telemarketing', 'depressed', 's-a-u-r-c-e', 'stooges', 'aww', 'but', 'coming', 'idioms', 'ideas', 'recruiter', 'something:', 'jeter', 'arm', 'aziz', 'noooooooooo', 'louder', 'krusty_the_clown:', \"'topes\", 'suds', 'young_marge:', 'enjoy', 'sent', 'overhearing', 'agents', 'rented', 'took', 'bartholomé:', 'hello', 'top', 'maiden', \"springfield's\", 'brotherhood', 'produce', 'brockman', 'therefore', 'been', 'bumbling', 'martini', 'op', 'r', 'geez', 'science', 'drederick', 'juice', 'lives', 'infiltrate', 'venture', 'drinking:', 'lump', 'glee', 'date', 'terrorizing', 'tyson/secretariat', 'parked', 'naegle', 'bash', 'payback', 'snorts', 'gum', \"children's\", 'little_hibbert_girl:', 'peanut', 'chateau', 'minutes', 'beef', \"drawin'\", \"leavin'\", 'stengel', 'eyed', 'evil', 'federal', 'design', 'polenta', 'benjamin', 'disturbance', 'reaches', \"today's\", 'store', 'settlement', 'supermarket', 'quebec', 'refreshingness', 'nitwit', 'mobile', 'dreams', 'while', 'rector', \"must've\", 'washed', 'twenty-two', 'designated', 'summer', 'lifestyle', 'couple', 'launch', 'whatsit', 'election', 'pantry', 'chain', \"stallin'\", 'stealings', 'lennyy', 'swings', 'slobbo', 'right-handed', 'strolled', 'flynt', 'bubbles', \"clancy's\", 'six', '&', 'ling', 'apron', 'renew', 'dumb-asses', 'rent', 'put', 'sunny', 'alley', 'hispanic_crowd:', 'baby', '250', 'liver', \"watchin'\", 'mock-up', \"murphy's\", 'blood-thirsty', 'running', 'pontiff', \"spiffin'\", 'shelf', 'itchy', 'painting', 'mamma', 'undermine', 'doreen:', 'dead', 'their', 'killing', 'pleased', 'excellent', 'lame', 'ivana', 'best', 'saved', 'case', 'sound', \"america's\", 'happens', \"ragin'\", 'purse', 'memories', 'betcha', 'milhouses', 'everything', \"depressin'\", 'charm', 'rest', \"haven't\", 'ees', 'coaster', 'beatings', 'consulting', 'barstools', 'daaaaad', 'earpiece', 'spectacular', \"don'tcha\", 'can', 'wrapped', 'wakede', 'trustworthy', 'underbridge', 'paramedic:', 'slap', '||rparenthese||', 'right', 'fierce', 'innocuous', 'fans', 'coupon', 'conspiratorial', \"'kay-zugg'\", 'moe-lennium', 'patron_#1:', 'music', 'folk', \"fightin'\", 'donut-shaped', 'dump', 'curious', 'shorter', 'champs', 'leak', 'network', 'nascar', 'cheap', 'awful', 'grabbing', 'unlike', 'worse', 'delightfully', 'saw', 'hit', 'stops', 'tough', 'microbrew', 'bunch', 'believe', 'adeleine', 'carlotta:', 'felony', 'war', 'spits', 'maman', 'cheaped', 'cheat', 'cuddling', 'donated', 'exits', 'somebody', 'illegal', 'my-y-y-y-y-y', 'lainie:', 'disgracefully', 'oblongata', 'troll', 'weekend', 'lifters', 'faced', 'eight-year-old', 'brockelstein', 'sacrilicious', 'terrific', 'correcting', 'banquet', 'carolina', 'sweetheart', 'carey', \"tomorrow's\", 'after', 'beer', 'barkeep', 'toe', 'forecast', 'non-american', 'honor', 'mop', 'sidekick', 'except', 'landfill', 'lovely', 'written', 'jacques', 'potato', 'hearts', 'leftover', 'thanks', \"fallin'\", 'yawns', 'errrrrrr', 'wish-meat', 'heather', 'creates', 'disaster', 'ingested', 'bras', 'seductive', 'patron_#2:', 'truck_driver:', 'candles', 'steaming', 'whirlybird', 'clap', \"drexel's\", 'terminated', 'minute', 'influence', 'fayed', 'manchego', 'grand', 'poin-dexterous', 'please', 'refiero', 'ziffcorp', 'drunkenly', 'straighten', 'too', 'touched', 'bounced', 'wake', 'inspired', 'trapped', 'multiple', 'anyhow', 'attraction', 'lecture', 'incarcerated', 'sucked', 'starlets', 'sexton', 'ancestors', 'poetics', 'happily:', 'ready', 'twelveball', 'hockey-fight', 'heave-ho', 'glad', 'happen', 'archaeologist', 'shoo', 'ah', 'hemoglobin', \"ma's\", 'cummerbund', 'quick-like', 'whoopi', 'snaps', 'absentmindedly', \"'your\", 'mild', \"narratin'\", 'rainforest', 'choice', 'sobo', 'name', \"cuckold's\", 'button-pusher', 'forty-two', 'himself', 'stop', \"i'd\", 'dreamed', 'pernt', 'cleaner', 'femininity', 'shaky', 'rolled', 'meals', 'sets', 'bronco', 'eurotrash', 'ribbon', 'prayers', 'forbids', 'superpower', 'mahatma', 'pfft', 'meaningless', 'microphone', 'heartless', 'sizes', 'predictable', 'blowfish', 'industry', 'entirely', 'cobra', 'cannot', 'wayne', 'militia', 'came', 'spews', \"chewin'\", 'thnord', 'jerk-ass', 'wuss', 'sperm', 'meaning', 'meet', 'gee', 'terrible', 'horrors', \"shan't\", \"professor's\", '21', 'lanes', \"daughter's\", 'heck', 'lowering', 'say', \"somethin':\", 'senators', 'customers-slash-only', 'shells', 'bonfire', 'duffman', 'premiering', 'nash', 'dying', 'impressed', \"round's\", 'doppler', 'sangre', 'friend:', 'adventure', 'blues', 'begin', 'stupid', 'fragile', \"lookin'\", 'manuel', 'background', 'ashamed', '7-year-old_brockman:', 'inspector', 'lone', 'fbi_agent:', 'disposal', 'stonewall', 'less', 'nightmares', 'flanders', 'orgasmville', 'mudflap', 'overflowing', 'vance', 'deal', 'snotball', 'bread', 'gossipy', 'chug-monkeys', 'vacations', 'hardy', 'sighs', 'parking', 'hammer', 'born', \"y'money's\", 'confession', 'ticks', 'finish', 'boozebag', 'press', 'piling', 'vehicle', 'woo', 'haws', 'english', 'stupidest', 'ding-a-ding-ding-a-ding-ding', 'standing', 'by', 'rhode', 'wondering', 'badly', 'skinner', 'positive', 'shape', 'west', 'wraps', 'key', 'wings', 'sieben-gruben', 'harv', 'arguing', 'th', 'on', 'laney', 'avenue', 'angry', 'dads', 'high-definition', 'courthouse', 'whiny', 'brawled', 'string', 'bunion', 'bad-mouth', 'tempting', 'huge', 'crawl', 'derisive', 'lindsay_naegle:', 'entrance', 'calvin', 'familiar', 'salvation', 'authenticity', 'guttural', 'amber_dempsey:', 'phone', 'gentle', 'warned', 'excuses', 'games', 'ball', \"won't\", 'lady_duff:', 'faces', 'distinct', 'blokes', 'smithers', 'smile', 'germans', 'remain', 'glitterati', 'human', 'abolish', 'understood:', 'caused', 'bagged', 'official', 'poisoning', 'arm-pittish', 'kiss', 'wang', 'woman_bystander:', 'washouts', 'vestigial', 'tapestry', 'rife', 'haikus', 'angrily', 'mid-conversation', \"callin'\", 'concerned', 'beer:', 'transmission', 'surprised/thrilled', 'neighbors', 'at', 'extra', 'amid', 'hell', 'nods', 'ford', 'sue', 'life-extension', 'papa', 'lessons', 'tip', 'canyonero', 'pre-columbian', 'african', 'president', 'continuing', 'mexican', 'ura', \"payin'\", 'slick', 'jackass', 'chicken', 'safecracker', 'helping', 'boxer:', 'france', 'corkscrew', 'sounded', 'swig', 'muscles', 'counting', 'dna', 'accelerating', 'defensive', 'likes', 'patented', 'here', 'enemies', 'rebuttal', 'jernt', 'tomato', 'tonight', 'milhouse_van_houten:', 'decent', 'invulnerable', 'uh-oh', 'squadron', \"ball's\", 'pip', 'propose', \"treatin'\", 'morning-after', 'ahhhh', 'connor-politan', \"somethin'\", 'celebrity', 'spitting', 'drag', 'brace', 'peaked', 'founded', 'pregnancy', 'grammys', 'sanctuary', 'compared', 'washer', 'alter', 'macho', 'schedule', 'yea', 'hub', 'sun', \"that's\", 'title:', 'american', \"when's\", 'mona_simpson:', 'engine', 'almond', 'crossed', 'stink', 'mistake', 'knuckle-dragging', 'publish', 'massachusetts', 'lou:', 'odd', 'get', 'bam', 'clearing', 'additional-seating-capacity', 'field', 'broke', 'flown', 'energy', 'aggie', 'weirder', \"liberty's\", 'project', 'spoken', 'throwing', 'allowed', 'schabadoo', 'certificate', 'site', \"they'd\", 'into', 'barney-guarding', 'ah-ha', \"kid's\", 'selma_bouvier:', 'interested', 'men', 'pulled', 'guy', 'fudd', 'skinny', 'handed', 'solid', 'ratted', 'allowance', 'cesss', 'kazoo', 'fan', 'hope', 'late', 'kim_basinger:', \"can't-believe-how-bald-he-is\", 'cheese', 'assumed', 'ingredient', 'signal', 'tab', 'uninhibited', 'idiots', 'gol-dangit', 'duff', 'hotel', 'says', 'sharps', 'joining', 'savvy', 'take-back', 'bender:', 'duty', 'sitting', 'ignorant', 'assert', 'ralph_wiggum:', 'thesaurus', 'atari', 'composite', 'raise', 'ehhhhhhhhh', 'beards', 'losers', 'waylon_smithers:', 'lizard', 'love', 'nerve', 'bright', 'sadistic_barfly:', 'bury', 'internet', 'dejected_barfly:', 'man_at_bar:', 'kirk', 'ridiculous', 'rid', 'town', 'flowers', 'certain', 'pas', 'uniforms', 'princesses', 'scornful', 'lifts', 'curds', 'runt', 'average', 'turning', 'billingsley', 'mike_mills:', 'dum-dum', 'poking', 'glowers', 'feet', 'peppy', 'bartending', 'unusual', 'driveability', '1-800-555-hugs', 'crunch', 'falsetto', 'to', 'pretentious_rat_lover:', 'bindle', 'cyrano', 'unattractive', 'help', 'elves:', 'plucked', 'try', 'hiya', 'owns', 'aging', 'smooth', 'dig', 'meaningfully', 'suspicious', 'huggenkiss', 'bathed', \"swishifyin'\", 'rag', 'quarry', 'ehhhhhhhh', 'well', 'certified', 'hawaii', 'carl:', 'employees', 'series', 'polite', 'commission', 'con', 'barney', 'barney_gumble:', 'e', 'ref', \"didn't\", 'ale', 'friendship', 'kicked', \"d'ya\", \"ol'\", 'formico:', 'served', 'offshoot', 'hats', 'youngsters', 'nah', 'slobs', 'lee', 'hank_williams_jr', 'clock', 'checks', 'mindless', 'shove', 'mistresses', 'worldly', 'tv_daughter:', 'parrot', 'stools', 'mid-seventies', 'age', 'powerful', 'aristotle:', 'coin', 'libido', 'apology', 'never', 'a-lug', 'christopher', 'years', 'ventriloquism', 'cooking', 'theme', 'mary', 'mmm-hmm', 'quit', 'moe-near-now', 'bugging', 'plywood', 'promise', 'cloudy', 'jackson', 'competing', 'chinese_restaurateur:', 'mimes', 'puke-holes', 'ballot', 'skin', 'testing', 'scores', 'ruuuule', 'group', 'videotaped', 'wish', 'punk', 'pillows', 'due', 'junior', 'chauffeur:', 'hot-rod', \"'ceptin'\", 'scanning', 'odor', 'shooting', 'beanbag', 'bones', 'unless', 'alone', 'blackjack', 'scare', 'grammar', 'ignoring', 'noises', 'tears', 'pro', \"yieldin'\", 'so-called', 'lists', 'equivalent', 'picture', 'marguerite:', 'hate-hugs', 'eighty-three', 'inning', 'also', 'smelling', 'expression', 'see', 'seems', 'hydrant', 'weapon', \"listenin'\", 'sass', 'irrelevant', 'lincoln', 'ripping', 'ali', 'bide', 'roomy', 'santeria', 'bitterly', 'invented', 'yells', 'aer', 'mixed', 'bridge', 'general', 'inquiries', 'edgy', 'astrid', 'smug', 'initially', 'called', 'philosophic', 'woman:', 'lie', 'arms', \"wife's\", 'newsletter', 'ourselves', 'self-made', 'applicant', 'deer', 'breakfast', 'break-up', 'bets', 'ore', 'calendars', 'film', 'host', 'white', 'brine', 'outlook', 'shop', 'y-you', 'gin', 'mess', 'choices:', 'squishee', 'sap', 'instrument', 'swell', 'aw', 'rotten', 'back', 'jacques:', 'sassy', 'already', 'feels', 'all:', 'rascals', 'sleeps', \"'roids\", 'chase', 'castle', \"smokin'_joe_frazier:\", 'pennies', 'therapist', 'super-tough', \"eatin'\", 'changes', 'espn', 'knocks', 'searching', 'fat', 'hitchhike', 'heard', 'inspection', 'merchants', 'wounds', 'tubman', 'affects', 'successful', 'overturned', 'grade', 'nailed', 'better', 'later', 'icelandic', 'clubs', 'hops', 'depending', 'peppers', 'ancient', 'voters', 'm', 'swooning', 'southern', '/mr', 'eaten', 'agree', 'allow', 'plum', 'goodwill', \"goin'\", 'electronic', 'diddilies', 'example', 'pirate', 'buried', 'garbage', 'fact', 'contact', 'popped', 'besides', 'lookalike', 'replace', 'wedding', 'want', \"y'see\", 'experiments', 'society', 'walked', 'nose', 'amnesia', 'bloodball', 'lucius:', 'gangrene', 'fritz', \"poundin'\", 'protesters', 'cracked', 'catching', 'all', 'coach:', 'our', 'exactly', 'carl', 'mis-statement', 'magnanimous', 'girlfriend', 'customers', 'easy-going', 'exhale', 'forget', 'linda', 'marjorie', 'adjourned', 'so', 'denver', 'perplexed', 'young_homer:', 'chief', 'will', 'infestation', 'yo', 'mabel', 'closes', 'living', 'sealed', 'gayer', 'illegally', 'cadillac', 'avalanche', 'song', 'worthless', 'therapy', \"aren'tcha\", 'backgammon', 'coughs', 'unlocked', 'sagacity', 'however', 'cozy', 'settled', 'victory', 'ton', 'per', 'lighten', 'understood', 'jeez', 'supply', 'gulliver_dark:', 'impeach', 'seen', 'pen', 'disco_stu:', 'limericks', 'prison', 'backwards', 'hates', 'rotch', 'wudgy', 'fevered', 'latour', 'ring', 'dilemma', 'obvious', 'limber', 'bachelorhood', 'majesty', 'scornfully', \"hell's\", 'flips', 'cream', 'teach', 'view', 'benjamin:', 'work', 'marge_simpson:', 'majority', 'cheated', 'fuss', 'buttocks', 'again', 'surgery', 'swimmers', 'doof', 'failure', 'jigger', 'yard', 'behind', 'catty', 'drollery', 'erasers', 'fixes', 'dislike', 'spine', 'shag', 'tow-joes', 'campaign', 'car', 'those', 'kept', 'kidding', 'prefer', 'unearth', 'continuum', 'etc', 'straining', 'theater', 'pants', 'bupkus', 'jay:', 'gums', 'irs', 'restroom', 'painless', 'ahhh', 'gifts', 'fulla', 'bartenders', 'wrote', 'socialize', 'pronounce', 'minors', 'steal', '_babcock:', 'eye-gouger', 'colorado', 'although', 'quitcher', 'adult', 'shaggy', 'horribilis', 'indecipherable', 'became', 'arrange', 'inexorable', 'scared', 'un-sults', \"smackin'\", 'assent', 'snackie', 'magazine', \"challengin'\", 'street', 'combination', 'patient', 'wolfe', 'jogging', 'brakes', 'einstein', 'pal', 'children', 'exclusive:', 'sensitivity', 'rude', 'sweetie', 'gluten', 'be-stainèd', 'secrets', 'radiation', 'special', 'dallas', 'original', 'inspiring', 'raggie', 'before', 'winston', 'breathtaking', 'exact', 'attack', 'save', 'freaky', 'drop-off', 'wooooo', 'uncomfortable', 'awkward', 'delicate', 'attention', 'rainier', 'stalwart', 'hers', 'pad', 'flame', 'bluff', 'fountain', 'witches', 'luckily', 'almost', 'spent', 'reconsidering', 'ripcord', 'dismissive', 'let', 'helen', 'woooooo', 'drawing', 'th-th-th-the', 'mommy', 'inspire', 'ping-pong', 'benefits', \"who'da\", 'these', 'amazed', 'legs:', 'tv_announcer:', 'asks', 're:', 'supreme', 'everyone', 'gorgeous', 'young_moe:', 'involved', 'railroad', \"sittin'\", 'wasting', 'starts', 'bedtime', 'shame', 'kneeling', 'good', 'wobbly', '||questionmark||', \"they'll\", 'grandiose', 'recorder', 'omigod', 'freely', 'pissed', 'pickled', 'nap', 'fish', 'excuse', 'totalitarians', 'displeased', 'speed', 'moe-ron', 'grubby', 'sounds', 'chanting', 'beached', 'bills', 'pulling', 'tablecloth', 'done:', 'shaken', 'calculate', 'tar-paper', 'notices', 'billion', 'ayyy', 'howya', 'wreck', 'walther_hotenhoffer:', 'boozy', 'thru', 'delays', 'jury', 'sistine', 'puke-pail', 'pridesters:', 'threw', 'happened', \"'tis\", 'set', 'players', 'radiator', 'de', 'joint', \"how'd\", 'protecting', 'year', 'exhaust', 'disco', 'intervention', \"man'd\", 'old-time', 'waylon', 'exchange', 'intriguing', 'weather', 'bald', 'lush', 'without:', 'flayvin', \"team's\", 'walks', 'shaved', 'thunder', \"playin'\", 'hushed', 'face', 'further', 'rekindle', 'accounta', 'imagine', 'fears', 'punch', 'politician', 'dispenser', 'way', 'nonchalantly', 'conversation', 'pointed', 'fat-free', 'ninth', 'sam:', 'winded', 'question', 'truth', 'totally', 'checking', \"dyin'\", 'resist', 'investor', 'clams', 'fine', 'push', 'lib', 'silent', 'dough', 'wussy', 'ineffective', 'boyfriend', 'feld', 'plan', 'drift', 'up', 'bride', 'hot', 'mate', 'buzziness', 'add', 'tiger', 'trolls', 'handler', 'winnings', 'many', 'head-gunk', 'laughing', 'americans', 'villanova', 'al', 'sports_announcer:', 'cheered', 'faint', 'regulations', 'introduce', 'szyslak', 'whee', 'noticing', 'were', 'beverage', 'has', \"gettin'\", 'raking', 'hangover', 'situation', 'beard', 'international', 'tells', 'orphan', 'expired', 'aid', 'lookalike:', 'listened', 'saint', 'quiet', 'stein-stengel-', 'cans', 'donation', 'rem', 'met', 'the_edge:', 'build', 'dizzy', 'matter-of-fact', 'infor', 'strain', 'bar-boy', \"sippin'\", '2', \"hadn't\", 'wood', 'statue', 'followed', 'deeply', 'yell', 'thing', 'light', 'bust', \"tv'll\", 'sing', 'senator', 'station', 'palm', 'michael', 'gotta', 'tonic', 'grave', 'fiiiiile', 'verdict', 'krusty', 'dials', 'apu', 'malibu', 'chug-a-lug', 'peeping', 'business', 'advance', 'stumble', 'sugar-me-do', 'fringe', 'haircuts', 'w-a-3-q-i-zed', 'shrieks', 'religious', 'anti-lock', \"table's\", 'throw', 'train', 'accusing', 'you', 'sickly', 'telephone', 'heart-broken', \"it's\", 'means', 'restaurant', 'aerospace', 'yelp', 'foibles', 'television', 'careful', 'whoever', 'list', 'completing', 'trashed', 'abe', 'dash', 'smoker', \"makin'\", 'camera', 'taylor', 'u2:', 'legally', 'singing/pushing', 'lessee', 'lowest', 'sly', 'boned', 'ralph', 'respect', 'smart', 'snatch', 'won', 'learn', 'harvard', 'tomahto', 'swamp', 'ripper', 'lucky', 'tentative', 'utility', 'congoleum', 'form', 'curiosity', 'b-day', \"ma'am\", 'spooky', \"town's\", 'fry', 'thirty-three', 'tinkle', 'over-pronouncing', 'cup', 'quickly', 'mirror', 'him', 'family', 'call', 'kucinich', 'wealthy', 'sequel', 'conditioning', 'frosty', \"somethin's\", 'trying', 'pills', 'kearney_zzyzwicz:', 'perhaps', 'whim', \"jimbo's_dad:\", 'dunno', 'atlanta', 'rush', 'grudgingly', \"mcstagger's\", 'squeal', 'manfred', 'stored', 'pour', 'somehow', 'whistling', 'lugs', 'information', 'cruise', \"renovatin'\", 'middle', 'ruined', 'awed', 'meant', \"that'll\", 'happier', '1973', 'fanciest', 'and-and', \"president's\", 'poorer', 'over', 'norway', 'listening', 'degradation', 'ape-like', 'fancy', 'progress', 'youuu', 'envy-tations', 'giggle', 'certainly', 'henry', 'cattle', 'clench', 'lis', 'monroe', 'ruint', 'bank', 'deserve', 'spit-backs', 'handling', 'ing', 'museum', 'slugger', 'death', 'color', 'nucular', 'going', 'measurements', 'owe', 'sad', 'her', 'extract', 'until', 'stay', 'hunka', 'retain', 'sat-is-fac-tion', 'fill', 'beat', 'chicks', 'leans', \"wouldn't\", 'two-drink', 'neat', 'naked', 'fall', 'rutabaga', 'cueball', 'hitler', 'everybody', 'cowardly', 'swigmore', 'teeth', 'gr-aargh', 'waters', 'abusive', 'feel', 'stripe', 'teenage_bart:', 'corn', 'doug:', 'easier', 'laramie', 'agent', 'indeedy', 'glasses', 'scream', 'tooth', 'gary:', \"c'mon\", 'hmmmm', 'scientists', \"messin'\", 'own', 'labor', 'lay', 'this:', 'hurry', 'saving', 'obama', 'decision', 'cookies', 'went', 'activity', 'stool', 'sanitary', 'sensible', 'reserve', 'whaddya', 'novelty', 'cowboy', 'tuna', 'bugs', 'suits', 'gives', 'rupert_murdoch:', '_hooper:', 'souped', 'booger', 'hounds', 'dating', 'delete', 'make:', 'slaps', 'resigned', 'pin', 'cute', 'trucks', 'stories', 'fridge', 'incapable', 'walk', 'wiener', 'breaks', 'county', 'spot', 'sumatran', 'transfer', 'fork', 'burger', 'today/', 'cent', 'nooo', 'offensive', 'jokes', \"toot's\", 'toys', 'gordon', 'recipe', 'piece', 'mission', 'disguise', 'dancing', 'filth', 'starve', 'er', 'carmichael', 'stomach', 'binoculars', 'intruding', 'quimby', 'shreda', 'world', 'actors', 'contemplated', 'hands', 'wieners', 'backward', 'nerd', 'prolonged', 'evils', 'promotion', 'insulin', 'oof', 'saturday', 'figure', 'raises', 'brilliant', 'made', 'tense', 'eww', 'paper', 'louie:', 'turn', 'woo-hoo', 'much', 'theatrical', 'season', 'ab', 'pardon', 'half-day', 'stern', 'chapstick', 'lenny_leonard:', 'clown', 'delivery_boy:', 'glen:', 'pets', 'decency', 'booze', 'scoffs', 'chastity', 'no', 'neither', 'freaking', 'absorbent', 'slender', 'scrutinizing', 'gargoyles', \"'s\", 'loathe', 'somewhere', 'found', 'lime'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(data_dir, token_lookup, create_lookup_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint. If you ever decide to come back to this notebook or have to restart the notebook, you can start from here. The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import helper\n",
    "import numpy as np\n",
    "import problem_unittests as tests\n",
    "\n",
    "int_text, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6779"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(int_to_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the Neural Network\n",
    "You'll build the components necessary to build a RNN by implementing the following functions below:\n",
    "- get_inputs\n",
    "- get_init_cell\n",
    "- get_embed\n",
    "- build_rnn\n",
    "- build_nn\n",
    "- get_batches\n",
    "\n",
    "### Check the Version of TensorFlow and Access to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biliuta/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/__main__.py:14: UserWarning: No GPU found. Please use a GPU to train your neural network.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer'\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input\n",
    "Implement the `get_inputs()` function to create TF Placeholders for the Neural Network.  It should create the following placeholders:\n",
    "- Input text placeholder named \"input\" using the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) `name` parameter.\n",
    "- Targets placeholder\n",
    "- Learning Rate placeholder\n",
    "\n",
    "Return the placeholders in the following the tuple `(Input, Targets, LearingRate)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_inputs():\n",
    "    \"\"\"\n",
    "    Create TF Placeholders for input, targets, and learning rate.\n",
    "    :return: Tuple (input, targets, learning rate)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    inputs = tf.placeholder(tf.int32, shape=[None, None],name='input')\n",
    "    targets = tf.placeholder(tf.int32, shape=[None, None], name='target')\n",
    "    lrn_rate = tf.placeholder(tf.float32)\n",
    "    return (inputs, targets, lrn_rate)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_inputs(get_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Build RNN Cell and Initialize\n",
    "Stack one or more [`BasicLSTMCells`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicLSTMCell) in a [`MultiRNNCell`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/MultiRNNCell).\n",
    "- The Rnn size should be set using `rnn_size`\n",
    "- Initalize Cell State using the MultiRNNCell's [`zero_state()`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/MultiRNNCell#zero_state) function\n",
    "    - Apply the name \"initial_state\" to the initial state using [`tf.identity()`](https://www.tensorflow.org/api_docs/python/tf/identity)\n",
    "\n",
    "Return the cell and initial state in the following tuple `(Cell, InitialState)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_init_cell(batch_size, rnn_size):\n",
    "    \"\"\"\n",
    "    Create an RNN Cell and initialize it.\n",
    "    :param batch_size: Size of batches\n",
    "    :param rnn_size: Size of RNNs\n",
    "    :return: Tuple (cell, initialize state)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(rnn_size)\n",
    "    #drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([lstm] * 2)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    initial_state = tf.identity(initial_state, name=\"initial_state\")\n",
    "    return (cell, initial_state)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_init_cell(get_init_cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Word Embedding\n",
    "Apply embedding to `input_data` using TensorFlow.  Return the embedded sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def get_embed(input_data, vocab_size, embed_dim):\n",
    "    \"\"\"\n",
    "    Create embedding for <input_data>.\n",
    "    :param input_data: TF placeholder for text input.\n",
    "    :param vocab_size: Number of words in vocabulary.\n",
    "    :param embed_dim: Number of embedding dimensions\n",
    "    :return: Embedded input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    embeddings = tf.Variable(tf.random_uniform((vocab_size, embed_dim), -1.0, 1.0))\n",
    "    \n",
    "    embd = tf.nn.embedding_lookup(embeddings, input_data)\n",
    "    \n",
    "    return embd\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_embed(get_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Build RNN\n",
    "You created a RNN Cell in the `get_init_cell()` function.  Time to use the cell to create a RNN.\n",
    "- Build the RNN using the [`tf.nn.dynamic_rnn()`](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn)\n",
    " - Apply the name \"final_state\" to the final state using [`tf.identity()`](https://www.tensorflow.org/api_docs/python/tf/identity)\n",
    "\n",
    "Return the outputs and final_state state in the following tuple `(Outputs, FinalState)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def build_rnn(cell, inputs):\n",
    "    \"\"\"\n",
    "    Create a RNN using a RNN Cell\n",
    "    :param cell: RNN Cell\n",
    "    :param inputs: Input text data\n",
    "    :return: Tuple (Outputs, Final State)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    outputs, final_state = tf.nn.dynamic_rnn(cell, inputs,dtype=tf.float32)\n",
    "    final_state = tf.identity(final_state, name=\"final_state\")\n",
    "    \n",
    "    return (outputs, final_state)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_build_rnn(build_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Build the Neural Network\n",
    "Apply the functions you implemented above to:\n",
    "- Apply embedding to `input_data` using your `get_embed(input_data, vocab_size, embed_dim)` function.\n",
    "- Build RNN using `cell` and your `build_rnn(cell, inputs)` function.\n",
    "- Apply a fully connected layer with a linear activation and `vocab_size` as the number of outputs.\n",
    "\n",
    "Return the logits and final state in the following tuple (Logits, FinalState) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def build_nn(cell, rnn_size, input_data, vocab_size):\n",
    "    \"\"\"\n",
    "    Build part of the neural network\n",
    "    :param cell: RNN cell\n",
    "    :param rnn_size: Size of rnns\n",
    "    :param input_data: Input data\n",
    "    :param vocab_size: Vocabulary size\n",
    "    :return: Tuple (Logits, FinalState)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    emb_input = get_embed(input_data, vocab_size, 200)\n",
    "    outputs, finalst = build_rnn(cell=cell, inputs=emb_input)\n",
    "    full_output = tf.contrib.layers.fully_connected(outputs,vocab_size, \n",
    "                                             activation_fn=None)\n",
    "    \n",
    "    return full_output, finalst\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_build_nn(build_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Batches\n",
    "Implement `get_batches` to create batches of input and targets using `int_text`.  The batches should be a Numpy array with the shape `(number of batches, 2, batch size, sequence length)`. Each batch contains two elements:\n",
    "- The first element is a single batch of **input** with the shape `[batch size, sequence length]`\n",
    "- The second element is a single batch of **targets** with the shape `[batch size, sequence length]`\n",
    "\n",
    "If you can't fill the last batch with enough data, drop the last batch.\n",
    "\n",
    "For exmple, `get_batches([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], 2, 3)` would return a Numpy array of the following:\n",
    "```\n",
    "[\n",
    "  # First Batch\n",
    "  [\n",
    "    # Batch of Input\n",
    "    [[ 1  2  3], [ 7  8  9]],\n",
    "    # Batch of targets\n",
    "    [[ 2  3  4], [ 8  9 10]]\n",
    "  ],\n",
    " \n",
    "  # Second Batch\n",
    "  [\n",
    "    # Batch of Input\n",
    "    [[ 4  5  6], [10 11 12]],\n",
    "    # Batch of targets\n",
    "    [[ 5  6  7], [11 12 13]]\n",
    "  ]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def get_batches(int_text, batch_size, seq_length):\n",
    "    \"\"\"\n",
    "    Return batches of input and target\n",
    "    :param int_text: Text with the words replaced by their ids\n",
    "    :param batch_size: The size of batch\n",
    "    :param seq_length: The length of sequence\n",
    "    :return: Batches as a Numpy array\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    text_len = len(int_text)\n",
    "    elems_per_batch = (batch_size* seq_length)\n",
    "    num_batches = math.floor(text_len/elems_per_batch)\n",
    "    \n",
    "    #print(num_batches)\n",
    "    \n",
    "    int_text = int_text[:num_batches*batch_size*seq_length+1]\n",
    "    \n",
    "    batches = np.zeros(shape=(num_batches,2,batch_size,seq_length))\n",
    "    \n",
    "    #print(int_text)\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        for j in range(batch_size):\n",
    "            idx = i*seq_length + j*num_batches*seq_length\n",
    "            x= int_text[idx:idx+seq_length]\n",
    "            y= int_text[idx+1:idx+seq_length+1]\n",
    "            #print(i,\" \",j,\" \",x)\n",
    "            batches[i,0,j] = x\n",
    "            batches[i,1,j] = y\n",
    "    \n",
    "    #print(batches)\n",
    "    \n",
    "    return batches\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_batches(get_batches)\n",
    "#get_batches([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], 2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Neural Network Training\n",
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "\n",
    "- Set `num_epochs` to the number of epochs.\n",
    "- Set `batch_size` to the batch size.\n",
    "- Set `rnn_size` to the size of the RNNs.\n",
    "- Set `seq_length` to the length of sequence.\n",
    "- Set `learning_rate` to the learning rate.\n",
    "- Set `show_every_n_batches` to the number of batches the neural network should print progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Number of Epochs\n",
    "num_epochs = 10\n",
    "# Batch Size\n",
    "batch_size = 128\n",
    "# RNN Size\n",
    "rnn_size = 512\n",
    "# Sequence Length\n",
    "seq_length = 120\n",
    "# Learning Rate\n",
    "learning_rate = 0.001\n",
    "# Show stats for every n number of batches\n",
    "show_every_n_batches = 2\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "save_dir = './save'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Build the Graph\n",
    "Build the graph using the neural network you implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "from tensorflow.contrib import seq2seq\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    vocab_size = len(int_to_vocab)\n",
    "    input_text, targets, lr = get_inputs()\n",
    "    input_data_shape = tf.shape(input_text)\n",
    "    cell, initial_state = get_init_cell(input_data_shape[0], rnn_size)\n",
    "    logits, final_state = build_nn(cell, rnn_size, input_text, vocab_size)\n",
    "\n",
    "    # Probabilities for generating words\n",
    "    probs = tf.nn.softmax(logits, name='probs')\n",
    "\n",
    "    # Loss function\n",
    "    cost = seq2seq.sequence_loss(\n",
    "        logits,\n",
    "        targets,\n",
    "        tf.ones([input_data_shape[0], input_data_shape[1]]))\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "    # Gradient Clipping\n",
    "    gradients = optimizer.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients]\n",
    "    train_op = optimizer.apply_gradients(capped_gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train\n",
    "Train the neural network on the preprocessed data.  If you have a hard time getting a good loss, check the [forms](https://discussions.udacity.com/) to see if anyone is having the same problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch    0/4   train_loss = 8.822\n",
      "Epoch   0 Batch    2/4   train_loss = 8.556\n",
      "Epoch   1 Batch    0/4   train_loss = 7.526\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-396c263e7e73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0minitial_state\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 lr: learning_rate}\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# Show every <show_every_n_batches> batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/biliuta/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/biliuta/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/biliuta/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/biliuta/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/biliuta/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "batches = get_batches(int_text, batch_size, seq_length)\n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch_i in range(num_epochs):\n",
    "        state = sess.run(initial_state, {input_text: batches[0][0]})\n",
    "\n",
    "        for batch_i, (x, y) in enumerate(batches):\n",
    "            feed = {\n",
    "                input_text: x,\n",
    "                targets: y,\n",
    "                initial_state: state,\n",
    "                lr: learning_rate}\n",
    "            train_loss, state, _ = sess.run([cost, final_state, train_op], feed)\n",
    "\n",
    "            # Show every <show_every_n_batches> batches\n",
    "            if (epoch_i * len(batches) + batch_i) % show_every_n_batches == 0:\n",
    "                print('Epoch {:>3} Batch {:>4}/{}   train_loss = {:.3f}'.format(\n",
    "                    epoch_i,\n",
    "                    batch_i,\n",
    "                    len(batches),\n",
    "                    train_loss))\n",
    "\n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, save_dir)\n",
    "    print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Save Parameters\n",
    "Save `seq_length` and `save_dir` for generating a new TV script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Save parameters for checkpoint\n",
    "helper.save_params((seq_length, save_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import helper\n",
    "import problem_unittests as tests\n",
    "\n",
    "_, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()\n",
    "seq_length, load_dir = helper.load_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Generate Functions\n",
    "### Get Tensors\n",
    "Get tensors from `loaded_graph` using the function [`get_tensor_by_name()`](https://www.tensorflow.org/api_docs/python/tf/Graph#get_tensor_by_name).  Get the tensors using the following names:\n",
    "- \"input:0\"\n",
    "- \"initial_state:0\"\n",
    "- \"final_state:0\"\n",
    "- \"probs:0\"\n",
    "\n",
    "Return the tensors in the following tuple `(InputTensor, InitialStateTensor, FinalStateTensor, ProbsTensor)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_tensors(loaded_graph):\n",
    "    \"\"\"\n",
    "    Get input, initial state, final state, and probabilities tensor from <loaded_graph>\n",
    "    :param loaded_graph: TensorFlow graph loaded from file\n",
    "    :return: Tuple (InputTensor, InitialStateTensor, FinalStateTensor, ProbsTensor)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    inp=loaded_graph.get_tensor_by_name(\"input:0\")\n",
    "    inits=loaded_graph.get_tensor_by_name(\"initial_state:0\")\n",
    "    fs=loaded_graph.get_tensor_by_name(\"final_state:0\")\n",
    "    probs=loaded_graph.get_tensor_by_name(\"probs:0\")\n",
    "    return inp, inits, fs, probs\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_tensors(get_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Choose Word\n",
    "Implement the `pick_word()` function to select the next word using `probabilities`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def pick_word(probabilities, int_to_vocab):\n",
    "    \"\"\"\n",
    "    Pick the next word in the generated text\n",
    "    :param probabilities: Probabilites of the next word\n",
    "    :param int_to_vocab: Dictionary of word ids as the keys and words as the values\n",
    "    :return: String of the predicted word\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return int_to_vocab[probabilities.argmax(axis=0)]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_pick_word(pick_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Generate TV Script\n",
    "This will generate the TV script for you.  Set `gen_length` to the length of TV script you want to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "gen_length = 200\n",
    "# homer_simpson, moe_szyslak, or Barney_Gumble\n",
    "prime_word = 'moe_szyslak'\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_dir + '.meta')\n",
    "    loader.restore(sess, load_dir)\n",
    "\n",
    "    # Get Tensors from loaded model\n",
    "    input_text, initial_state, final_state, probs = get_tensors(loaded_graph)\n",
    "\n",
    "    # Sentences generation setup\n",
    "    gen_sentences = [prime_word + ':']\n",
    "    prev_state = sess.run(initial_state, {input_text: np.array([[1]])})\n",
    "\n",
    "    # Generate sentences\n",
    "    for n in range(gen_length):\n",
    "        # Dynamic Input\n",
    "        dyn_input = [[vocab_to_int[word] for word in gen_sentences[-seq_length:]]]\n",
    "        dyn_seq_length = len(dyn_input[0])\n",
    "\n",
    "        # Get Prediction\n",
    "        probabilities, prev_state = sess.run(\n",
    "            [probs, final_state],\n",
    "            {input_text: dyn_input, initial_state: prev_state})\n",
    "        \n",
    "        pred_word = pick_word(probabilities[dyn_seq_length-1], int_to_vocab)\n",
    "\n",
    "        gen_sentences.append(pred_word)\n",
    "    \n",
    "    # Remove tokens\n",
    "    tv_script = ' '.join(gen_sentences)\n",
    "    for key, token in token_dict.items():\n",
    "        ending = ' ' if key in ['\\n', '(', '\"'] else ''\n",
    "        tv_script = tv_script.replace(' ' + token.lower(), key)\n",
    "    tv_script = tv_script.replace('\\n ', '\\n')\n",
    "    tv_script = tv_script.replace('( ', '(')\n",
    "        \n",
    "    print(tv_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# The TV Script is Nonsensical\n",
    "It's ok if the TV script doesn't make any sense.  We trained on less than a megabyte of text.  In order to get good results, you'll have to use a smaller vocabulary or get more data.  Luckly there's more data!  As we mentioned in the begging of this project, this is a subset of [another dataset](https://www.kaggle.com/wcukierski/the-simpsons-by-the-data).  We didn't have you train on all the data, because that would take too long.  However, you are free to train your neural network on all the data.  After you complete the project, of course.\n",
    "# Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as \"dlnd_tv_script_generation.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\". Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
